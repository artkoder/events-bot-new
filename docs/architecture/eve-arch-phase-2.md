# EVE Frameworks — Фаза 2 (Архитектурный анализ)

Цель фазы: предложить 2–3 варианта архитектуры для `EVE-11` (лимиты), `EVE-54` (секреты в Kaggle), `EVE-55` (Gemma), оценить риски гонок и зафиксировать Postgres-паттерн атомарности.

## 1) Требования и ограничения (сводка)

Нужно обеспечить:
- глобальный контроль лимитов Google AI (Gemma/Gemini): `RPM`, `TPM`, `RPD`;
- несколько ключей (pool), единая точка правды по лимитам/метаданным в Supabase;
- атомарное резервирование (check+increment) без гонок при параллельных запросах;
- ретраи провайдера до 3 раз, перед каждой попыткой — проверка/резервирование лимитов;
- режимы ожидания `WAIT` / `NO_WAIT`;
- полный аудит: успехи, провайдерные ошибки, и блокировки по лимитам (с `retry_after_ms`).

## 2) Архитектурные варианты (2–3)

### Вариант A — Общая библиотека (SDK) + Supabase RPC (без gateway)

**Идея:** все потребители (бот, скрипты, фоновые задачи) подключают общий модуль `google_ai_client`, который перед вызовом Google SDK делает `reserve` через Postgres RPC, затем вызывает провайдера и делает `finalize`.

**Плюсы**
- минимальная инфраструктура: нет отдельного сервиса;
- проще внедрять в существующий Python-код (в т.ч. unit тесты вокруг SDK).

**Минусы / риски**
- проблема секретов для Kaggle: если RPC возвращает выбор ключа из пула, клиент должен уметь получить **конкретный** ключ (иначе нельзя распределять нагрузку).
- если придерживаться текущей идеи “ключи не в БД, только `env_var_name`”, то каждый consumer должен иметь *все* ключи в окружении; для Kaggle это обычно нежелательно.

**Когда подходит**
- если согласовано, что ключи действительно лежат у каждого потребителя (или у всех нужных потребителей);
- если Kaggle будет ходить не в Google напрямую, а через другой механизм (см. Вариант B/C).

### Вариант B — Централизованный gateway-сервис (`ai-gateway`) + Supabase RPC

**Идея:** поднять отдельный HTTP-сервис (или выделенный роут в текущем aiohttp приложении), который:
1) принимает запрос “сделай LLM вызов” (`model`, payload, planned tokens, `WAIT/NO_WAIT`, метаданные);
2) атомарно резервирует лимиты в Supabase (RPC);
3) выбирает и применяет конкретный Google API key из своего key pool;
4) выполняет реальный вызов Google SDK;
5) пишет финальный audit (finalize/reconcile) и отдаёт результат клиенту.

**Плюсы**
- решает `EVE-54` максимально безопасно: Kaggle не хранит Google API keys, достаточно токена/ключа доступа к gateway;
- единая реализация ретраев, аудита, формата логов, извлечения usage из ответов провайдера;
- проще обеспечивать инварианты и проводить нагрузочные тесты.

**Минусы / риски**
- дополнительная инфраструктура (деплой/мониторинг), необходимость аутентификации клиентов;
- latency и потенциальный SPOF (нужны таймауты/ретраи/health).

**Когда подходит**
- если допустимо, что Kaggle/скрипты имеют сетевой доступ к gateway;
- если безопасность ключей важнее “прямых вызовов из ноутбука”.

### Вариант C — Supabase Edge Function (gateway внутри Supabase)

**Идея:** реализовать gateway как Supabase Edge Function:
- функция вызывает Postgres RPC для reserve/finalize,
- хранит key pool в Supabase secrets (или интеграции),
- предоставляет HTTP endpoint для бота и Kaggle.

**Плюсы**
- минимум собственной инфраструктуры: ближе к БД и “единой точке правды”;
- проще секрет-менеджмент (в рамках Supabase).

**Минусы / риски**
- ограничения платформы/рантайма (Deno, cold start, лимиты времени);
- сложнее дебажить и тестировать локально, чем Python-сервис;
- интеграция с Google SDK может потребовать особой обвязки (зависит от доступных библиотек).

**Когда подходит**
- если команда уже использует Edge Functions и устраивают их ограничения;
- если хочется держать “контроль + секреты” максимально рядом с Supabase.

## 3) Компоненты системы (логическая декомпозиция)

Независимо от выбранного варианта (SDK/gateway), удобно мыслить в терминах одинаковых компонентов:

1. **Limiter Store (Supabase)**
   - таблицы лимитов (`google_ai_model_limits`) и ключей (`google_ai_api_keys`);
   - счётчики/окна (`google_ai_usage_counters` или разбиение на minute/day);
   - audit-таблица событий (потребуется для “полного логирования”, сейчас в скриншоте её нет).
2. **Atomic Reserve API (Postgres RPC)**
   - `reserve_google_ai_capacity(...)` возвращает либо `ok + api_key_id + snapshots`, либо `blocked + retry_after_ms` (minute), либо `blocked_day`.
3. **Provider Client**
   - реальный вызов Google AI SDK (Gemma/Gemini);
   - извлечение фактических usage токенов (если доступны) и `provider_request_id`.
4. **Finalize/Reconcile API (Postgres RPC)**
   - `finalize_google_ai_usage(...)` фиксирует фактические токены/статус и, при необходимости, компенсирует разницу planned vs actual.

## 4) Риски гонок и рекомендованный Postgres-паттерн

### 4.1. Ключевой инвариант

Критический путь “проверить остатки → списать” должен быть **атомарным** в Postgres. Любые схемы “SELECT остатки → потом UPDATE” без блокировок приведут к гонкам.

### 4.2. Рекомендованный паттерн: RPC `reserve_*` = транзакция + условный upsert

**Цель:** одним вызовом определить `api_key_id` и выполнить `check+increment` так, чтобы при конкуренции “лишний” запрос просто не смог увеличить счётчики.

Рекомендованный скелет внутри RPC:

1. Взять “время БД” и вычислить окна:
   - `minute_bucket := date_trunc('minute', clock_timestamp())`
   - `day_bucket := (clock_timestamp() at time zone 'UTC')::date` (или согласованный TZ)
2. Прочитать лимиты модели из `google_ai_model_limits` (rpm/tpm/rpd).
3. Выбрать кандидатов ключей из `google_ai_api_keys`:
   - `where is_active = true and provider = 'google_ai'`
   - `order by priority asc, id asc` (или более сложная политика)
4. Для каждого кандидата попытаться сделать “условное списание”:
   - через `INSERT ... ON CONFLICT ... DO UPDATE` с `WHERE`-предикатом вида:
     - `rpm_used + planned_requests <= rpm_limit`
     - `tpm_used + planned_tokens <= tpm_limit`
     - `rpd_used + planned_requests <= rpd_limit` (дневной счётчик — отдельно или в рамках согласованной схемы)
   - если `ROW_COUNT = 1`, резервирование успешно → вернуть выбранный `api_key_id` и снимки.
5. Если ни один ключ не подошёл:
   - вернуть `blocked_day` если дневной лимит исчерпан на всех ключах;
   - иначе `blocked_minute` и `retry_after_ms`, вычисленный от времени БД до следующей минуты.

Почему это работает против гонок:
- условный `UPDATE ... WHERE rpm_used + X <= limit` гарантирует, что два конкурирующих запроса не смогут оба “проскочить” лимит: один обновит строку, второй получит `ROW_COUNT = 0` и будет вынужден выбрать другой ключ или вернуться blocked.

### 4.3. Альтернатива: advisory locks на (api_key_id, bucket)

Можно упростить код внутри RPC (особенно при неоднозначностях текущей схемы) через:
- `pg_advisory_xact_lock(hash(api_key_id, model, minute_bucket))`

Плюсы: проще reasoning, меньше сложных upsert-условий. Минусы: риск снижения параллелизма при узких ключах.

### 4.4. Что делать с `planned` vs `actual` (reconcile)

Практический вариант:
- `reserve` делает консервативное списание `planned_tokens = planned_input_tokens + planned_max_output_tokens`.
- `finalize`:
  - если `actual_total_tokens` известен и меньше planned → корректирует `tpm_used` вниз (в рамках того же `minute_bucket` и модели);
  - если `actual_total_tokens` неизвестен → фиксирует флаг `actual_tokens_unknown=true` и считает planned фактом (политика должна быть согласована).

Критичный риск: если `actual > planned`, это может привести к постфактум превышению TPM.
- Митигируется только политикой планирования: planned должен быть реальным верхним пределом (или иметь safety-ceiling).

### 4.5. Идемпотентность и “двойные списания”

Нужно поддержать `request_uid`:
- повторный `reserve` с тем же `request_uid` должен быть идемпотентным (вернуть тот же результат или safe no-op).
- это обычно требует отдельной таблицы “requests/reservations” с `UNIQUE(request_uid)` или лог-таблицы попыток с уникальным индексом.

Скриншотная схема таких таблиц не показывает → потребуется добавить (это уже предмет фазы 4).

## 5) Рекомендуемый выбор (предварительно) и причины

Без ответов на вопросы по Kaggle/секретам окончательный выбор делать рискованно, но предварительное предпочтение:

- Для `EVE-54` (секреты в Kaggle) наиболее согласованный по безопасности путь — **Вариант B (gateway)** или **Вариант C (edge function)**, чтобы Kaggle не содержал пул ключей.
- Для “внутренних” вызовов в боте можно:
  - либо также ходить через gateway (унификация),
  - либо использовать SDK (Вариант A) при условии, что бот имеет доступ ко всем ключам и политика секретов это допускает.

## 6) Промежуточный отчёт (Фаза 2)

Сформировано:
- 3 рабочих варианта (SDK / gateway / edge function) с привязкой к требованиям EVE-11/54/55.
- Рекомендованный Postgres-паттерн атомарности: единый RPC `reserve_*` в транзакции с условным upsert (и вычислением bucket’ов от времени БД); альтернатива — advisory locks.
- Выделены “обязательные” недостающие элементы схемы для идемпотентности и полного аудита (таблица запросов/событий), которые нужно будет подтвердить и спроектировать в фазе 4.

