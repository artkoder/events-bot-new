# Telegram Monitoring (мониторинг Telegram-источников)

> **Linear:** EVE-51  
> **Status:** Planning / Prototype in progress  
> **Цель:** раз в сутки автоматически находить анонсы событий в Telegram (каналы/группы) и **автоматически** добавлять/мержить их в БД бота (без модерации).

## 0. Что считаем “Telegram-источником”

Поддерживаем публичные:

- каналы
- группы / супергруппы (в т.ч. ссылки на конкретное сообщение)

Форматы, которые принимает UI и которые должны быть нормализованы в единый вид:

- `@username`
- `https://t.me/username`
- `https://t.me/username/<message_id>` (пример: `https://t.me/klassster/8809`)

**Нормализация:** везде приводим к `username` + опциональный `message_id` (для ссылок на сообщение).

## 1. High-level пайплайн

1) **Bot (server)**: по расписанию запускает Kaggle kernel `TelegramMonitor`.
2) **Kaggle**: Telethon читает сообщения источников, скачивает медиа, **заливает все картинки на Catbox**, делает OCR/извлечение событий (Gemma) и пишет результат `telegram_results.json`.
3) **Bot (server)**: забирает `telegram_results.json` и прогоняет каждый найденный event-candidate через **Интеллектуальный импорт** (см. `docs/backlog/features/smart-event-update/README.md`):
   - если событие новое → создаёт запись;
   - если событие уже есть → мерджит (обогащает) и добавляет источник.

## 2. Расписание (ежедневный запуск)

Требование: запуск **раз в сутки**, время выбираем так, чтобы не пересекалось с другими тяжёлыми джобами (`/parse`, `/3di`, видео-рендеры).

### Предлагаемые ENV

- `ENABLE_TG_MONITORING=1`
- `TG_MONITORING_TIME_LOCAL=23:40` (дефолт, можно изменить)
- `TG_MONITORING_TZ=Europe/Kaliningrad`

Поведение планировщика:

- `max_instances=1`, `coalesce=True` (не запускать второй раз параллельно)
- при отключении (`ENABLE_TG_MONITORING!=1`) отправлять алерт в админ-чат (как и остальные scheduled jobs)

## 3. Идемпотентность (самое важное)

### 3.1. Не перерабатывать уже просканированные сообщения

Если пост/сообщение (`source` + `message_id`) уже был обработан ранее, он **не должен** повторно прогоняться через импорт/LLM.

**Минимально необходимое хранение:**

- таблица `telegram_scanned_message` (см. ниже)
- на уровне Kaggle: использовать `min_id` (или эквивалент) и не тянуть историю глубоко, но всё равно оставляем серверную проверку как “последнюю линию защиты”.

### 3.2. Дедуп по картинкам (оптимизация нагрузки)

Если новый источник/пост не приносит **новых** изображений (афиш), то тяжёлый “интеллектуальный импорт” можно не запускать:

- источник всё равно добавляем в `event_source`;
- мердж описания/фактов/LLM пропускаем, если нет новых картинок и текст не дал новых фактов (эвристика на сервере).

**Как сравнивать картинки:**

- основной ключ: `sha256` (строгое совпадение байт);
- дополнительно (желательно): `pHash` (перцептивный хеш) для “перезалитых”/перекодированных изображений;
- если для старых событий нет `EventPoster` записей, допустим fallback: достать Catbox URL’ы из Telegraph страницы события и сравнить с новыми (best-effort).

## 4. Данные, которые обязаны дойти до сервера (формат результата)

Kaggle пишет один файл `telegram_results.json` со списком **сообщений** и извлечённых из них событий (в одном сообщении может быть много событий).

Минимальный контракт (v1):

```json
{
  "schema_version": 1,
  "run_id": "uuid",
  "generated_at": "2026-01-26T01:23:45Z",
  "messages": [
    {
      "source_username": "klassster",
      "source_type": "channel|group|supergroup|unknown",
      "message_id": 8809,
      "message_date": "2026-01-25T18:40:00Z",
      "source_link": "https://t.me/klassster/8809",
      "text": "оригинальный текст",
      "metrics": {
        "views": 1500,
        "likes": 45,
        "channel_median_views": 1000,
        "channel_median_likes": 20
      },
      "posters": [
        {
          "catbox_url": "https://files.catbox.moe/xyz.jpg",
          "sha256": "hex",
          "phash": "hex-or-null",
          "ocr_text": "text-or-null",
          "ocr_title": "title-or-null"
        }
      ],
      "events": [
        {
          "title": "string",
          "date": "YYYY-MM-DD",
          "time": "HH:MM-or-empty",
          "end_date": "YYYY-MM-DD-or-null",
          "location_name": "string-or-empty",
          "location_address": "string-or-null",
          "city": "string-or-null",
          "ticket_link": "url-or-null",
          "ticket_price_min": 0,
          "ticket_price_max": 0,
          "raw_excerpt": "text-or-null"
        }
      ]
    }
  ],
  "stats": {
    "sources_total": 0,
    "messages_scanned": 0,
    "messages_with_events": 0,
    "events_extracted": 0
  }
}
```

Примечания:

- `metrics.*` могут быть `null`, особенно для групп (где просмотры/лайки могут отсутствовать).
- `posters[]` всегда содержит **Catbox URL** (бот потом не сможет достать картинки из чужих чатов).
- `events[]` может быть пустым — тогда сообщение считается “просканировано”, но без событий.

## 5. Логика Kaggle ноутбука (детерминированно)

### 5.1. Выборка сообщений

Для каждого источника:

- читать новые сообщения после `last_scanned_message_id` (если есть)
- иначе: брать “умеренную глубину” (по умолчанию: последние 50 сообщений или последние 3 суток — что наступит раньше)
- между запросами делать небольшие случайные задержки (human-like)

### 5.2. Медиа

Для каждого сообщения:

- **не скачивать** медиа, если сообщение не пойдёт в импорт:
  - сначала пытаемся извлечь события по тексту (без OCR);
  - если текст короткий/пустой, но есть изображения — допускается OCR 1-й картинки как “детектор” (после OCR повторить извлечение);
  - если событий нет → не тратим трафик на скачивание/загрузку остальных картинок.
- если сообщение содержит события и будет обработано:
  - скачиваем изображения **лениво** и только те, которые будем добавлять через Smart Update (афиши/релевантные картинки; “рандомные фото/мемы” пропускаем best-effort);
  - для каждого выбранного изображения:
    - скачать bytes;
    - вычислить `sha256` (+ желательно `pHash`);
    - **залить на Catbox** (обязательно, т.к. бот не сможет скачать фото из чужого чата);
    - (опционально) OCR через Gemma и сохранить `ocr_text/ocr_title`.

Примечание (ограничение): чтобы честно сравнивать с уже имеющимися афишами события, нам нужен `sha256` (считается по скачанным байтам). Поэтому “не скачивать дубли” возможно только частично (например, не скачивать картинки, если сообщение вообще не импортируем).

### 5.3. Извлечение событий (Gemma)

Требование: поддержать **много событий в одном сообщении**.

Gemma возвращает массив событий. Минимальные обязательные поля: `title`, `date` (ISO). Остальные поля — best-effort.

## 6. Серверная часть: обработка результата

### 6.1. Отсечка “уже было”

Перед обработкой каждого `message`:

- проверить `telegram_scanned_message` по `(source_username, message_id)` (или через `source_id`)
- если уже есть запись со статусом `done` → пропустить обработку (но логировать счётчик “skipped_already_scanned”)

### 6.2. Прогон через Интеллектуальный импорт

Каждый элемент `events[]` должен быть обработан через “Smart Event Update”:

- создать/найти target event
- мерджить описание/факты/билеты/картинки по правилам
- добавить источник `source_link` в список источников события

Примечание: матчинг учитывает флаг площадки `allow_parallel_events` (см. `docs/reference/location-flags.md`).

### 6.3. Отчёт в админ-чат

После завершения:

- сколько источников/сообщений просканировано
- сколько сообщений пропущено как “уже сканировали”
- сколько событий извлечено
- сколько событий создано / сколько смержено
- список ошибок (если были)

## 7. Модель данных (минимум)

### 7.1. `telegram_source`

Хранит список источников, управляется через `/tg`.

Рекомендуемые поля:

- `id` (PK)
- `username` (TEXT, unique)
- `enabled` (BOOL)
- `default_location` (TEXT, nullable)
- `default_ticket_link` (TEXT, nullable)
- `trust_level` (`high|medium|low`, nullable)
- `last_scanned_message_id` (INT, nullable)
- `last_scan_at` (TIMESTAMP, nullable)

Политика по умолчанию:

- для большинства Telegram-источников `trust_level=low`;
- для официальных источников (например, официальный канал площадки) `trust_level=high` и должен выставляться через `/tg` при добавлении/редактировании источника.

### 7.2. `telegram_scanned_message`

Идемпотентность обработки.

Рекомендуемые поля:

- `source_id` (FK → telegram_source.id)
- `message_id` (INT)
- `message_date` (TIMESTAMP, nullable)
- `processed_at` (TIMESTAMP)
- `status` (`done|error|skipped`)
- `events_extracted` (INT)
- `events_imported` (INT)

PK: `(source_id, message_id)`.

## 8. Безопасность секретов (Kaggle через API)

Ограничение: **Kaggle Secrets нельзя полагаться** (нельзя программно прокинуть через API во время запуска), поэтому доставляем секреты через приватные datasets.

Требование: **шифровать всё**, не только `TG_SESSION`.

### 8.1. Какие секреты нужны ноутбуку

- `TG_SESSION` (Telethon StringSession)
- `TG_API_ID`
- `TG_API_HASH`
- `GOOGLE_API_KEY` (Gemma via Google AI SDK)

### 8.2. Доставка секретов

Паттерн “split datasets”:

- Dataset A (cipher): содержит **один** файл с ciphertext (например `secrets.enc`) + (опционально) несекретный `config.json` без ключей.
- Dataset B (key): содержит **только** `fernet.key`.

Kernel должен быть `is_private=true`, datasets — `public=false`.

Подробности и общие правила: `docs/operations/kaggle-secrets.md`.

### 8.3. Анти-утечки

- не печатать `config.json`/секреты в stdout
- редактировать логи (masking)
- в отчётах в админ-чат не показывать значения секретов

## 9. Acceptance (Gherkin)

```gherkin
# language: ru
Функция: Telegram Monitoring (daily ingest)

  Сценарий: Ежедневный запуск импортирует новые события
    Дано настроены источники Telegram
    И настроены TG_SESSION, TG_API_ID, TG_API_HASH, GOOGLE_API_KEY
    Когда срабатывает ежедневный запуск мониторинга
    Тогда в админ-чат приходит отчёт "Telegram Monitoring"
    И новые события появляются в базе

  Сценарий: Повторный запуск не создаёт дубликаты сообщений
    Дано мониторинг уже обработал сообщение "https://t.me/klassster/8809"
    Когда мониторинг запускается повторно
    Тогда сообщение не прогоняется через импорт повторно
    И в отчёте увеличивается счётчик skipped_already_scanned

  Сценарий: Одно сообщение содержит больше 5 событий
    Дано в источнике есть сообщение с 10 анонсами
    Когда мониторинг запускается
    Тогда все 10 событий обрабатываются и доходят до интеллектуального импорта
```
