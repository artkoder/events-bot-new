# Интеллектуальный импорт (Smart Event Update)

> **Linear:** EVE-60  
> **Status:** Planning / In design  
> **Цель:** автоматом мерджить одно событие из множества источников (VK, Telegram, сайты, ручной ввод) и формировать **наиболее полную** карточку события в боте.

## 0. Ключевые требования (как “контракт”)

1) **Без модерации и без UI мерджа**: всё работает автономно по правилам + LLM.
2) **Якорные поля не меняем** автоматически:
   - `date`, `time`, `location_name` (и связанные: `end_date`, `location_address`)  
   Менять их может только оператор через `/events -> Edit`.
3) **Противоречивое не добавляем**: если новая информация конфликтует с тем, что уже в событии (или с “каноническим” источником для этого факта), мы:
   - отбрасываем **только конфликтующий кусок**,
   - всё остальное из источника всё равно используем для обогащения.
4) **Событие имеет много источников**: сохраняем полный список источников и показываем его в `/events -> Edit`.
5) **Картинки — через Catbox** (источник может быть “чужой” для бота). Для дедупа используем хеши изображений.

## 0.1. Важная настройка: параллельные события на одной площадке

По умолчанию считаем, что площадка **не** проводит разные события в один `date/time` (и совпадение времени на одной площадке — сильный сигнал “это то же событие”).

Исключения — отдельные площадки (например, Научная библиотека), где реально бывают параллельные события. Для них включается флаг `allow_parallel_events=true` в `docs/reference/location-flags.md`.

## 1. Где используется

- Telegram Monitoring (см. `docs/backlog/features/telegram-monitoring/README.md`) — все извлечённые события проходят через Smart Update.
- VK intake (`/vk` → проверка → “Добавить”) — добавление/обновление событий должно идти через Smart Update.
- Ручное добавление события (диалог “/start → Добавить событие” / `/addevent`) — добавление/обновление событий должно идти через Smart Update.

**Инвариант:** любая новая информация о событии (любой источник) проходит через Smart Update, чтобы:

- не перезаписывать карточку “в лоб”,
- мерджить факты и картинки,
- сохранять список источников.

## 2. Модель данных

### 2.1. Источники события (`event_source`)

Нужна отдельная таблица (вместо одиночных полей `source_post_url`, `source_vk_post_url`):

- `id` (PK)
- `event_id` (FK → event.id)
- `source_type` (`telegram|vk|site|manual|other`)
- `source_url` (TEXT, unique в рамках `event_id`)
- `source_chat_username` (TEXT, nullable)
- `source_chat_id` (INT, nullable)
- `source_message_id` (INT, nullable)
- `imported_at` (TIMESTAMP)
- `trust_level` (`high|medium|low`, nullable) — если известен (например, для TG источников задаётся в `telegram_source`)

**Инвариант:** при любом успешном импорте мы добавляем `event_source` (если такого URL ещё нет).

### 2.2. Постеры (`EventPoster`)

Уже есть таблица `EventPoster` (см. `models.py`), используем её как каноническое хранилище картинок + OCR:

- ключ дедупа: `poster_hash` (sha256) + (опционально) `phash` как доп. поле/индекс в будущем
- `catbox_url` обязателен для всех импортов извне
- OCR (`ocr_text`, `ocr_title`) сохраняем, если он был получен на стороне Kaggle/импорта

## 3. Входные данные Smart Update

Smart Update работает с сущностями:

### 3.1. `EventCandidate` (то, что пришло “снаружи”)

Минимум:

- `source_type`
- `source_url` (например `https://t.me/<username>/<message_id>`)
- `source_text` (оригинальный текст)
- `extracted`: структурированные поля (если уже есть)
- `posters[]`: список изображений (`catbox_url`, `sha256`, `phash?`, `ocr_text?`)
- `metrics`: `views/likes/median_*` (опционально; для будущего скоринга)

### 3.2. “Ядро события” (то, что в БД)

Ключевые поля для матчинг/мерджа:

- `date`, `time`, `end_date`
- `location_name`
- `title`, `description`

## 4. Алгоритм (детерминированный)

### Шаг 0. Идемпотентность источника

Если `event_source` с таким `source_url` уже существует → **ничего не делаем** (это повторный импорт того же поста).

### Шаг 1. Поиск кандидатов на матчинг

Формируем shortlist существующих событий:

- сначала по дате/периоду:
  - `date == candidate.date` (или пересечение диапазона для `end_date`)
  - если `candidate.date` неизвестна → shortlist по ближайшим дням не строим (событие считаем “невалидным” и отбрасываем на входе)
- дополнительно фильтруем по:
  - `city` (если есть)
  - `location_name` (если есть)
  - `time` (если есть; точное совпадение как сильный сигнал, но само по себе недостаточно)

Перед вызовом LLM делаем быстрые “сильные” проверки:

- **Ticket link match:** если `candidate.ticket_link` совпадает с `event.ticket_link` (после нормализации URL) → это тот же event.
- **Poster hash match:** если пересечение `candidate.posters[].sha256` и `EventPoster.poster_hash` у события непустое → это тот же event (очень сильный сигнал).

### Шаг 1.1. Параллельные события (опция площадки) и multi-hall (anti-wrong-merge)

Некоторые площадки (пример: Научная библиотека) могут проводить **несколько разных событий одновременно** в одном `location_name` и в одно и то же `date/time`.

Опция включается только для отдельных площадок через `allow_parallel_events=true` в `docs/reference/location-flags.md`.

Если `allow_parallel_events=false` (по умолчанию):

- совпадение `date/time/location_name` — **сильный сигнал**, что это одно событие;
- создание второго события в тот же `date/time` на этой площадке допускается только при очень сильных причинах (например, явно разные афиши/разные ссылки и т.п.).

Если `allow_parallel_events=true`:

- совпадение `date/time/location_name` — **слабый сигнал** (на площадке реально могут быть параллельные события);
- поэтому матчинг и мердж должен быть более осторожным.

Правило безопасности (для `allow_parallel_events=true`): **не мерджить “только по времени и площадке”**, если в shortlist есть несколько событий с тем же `date/time/location_name`.

В таком случае матчинг допускается только при наличии сильного подтверждения:

- совпал `ticket_link`, или
- совпал `poster_hash` хотя бы по одной афише, или
- LLM вернул `confidence` очень высоким (см. порог ниже) и не указал альтернативы/сомнения в `reason_short`.

Дополнительно (рекомендуемый guard):

- извлечь из текста “уточнение места внутри площадки” (`hall_hint` / `room_hint`): слова вроде `зал`, `аудитория`, `лекторий`, `сцена`, `фойе`, `этаж`, `корпус` + ближайшие 1–3 слова;
- если и у кандидата, и у события есть `hall_hint`, и они различаются → **не мерджить** (скорее всего это разные параллельные события).

### Шаг 2. LLM-решение “это то же событие?”

LLM получает:

- `candidate` (структура + текст + OCR-тексты постеров + ссылки + метрики)
- `N` кандидатов из shortlist (N=10 максимум)

Требование: матчинг делается **по всей доступной информации**, а не только по названию/месту:

- сравниваем смысл, участников/персоналии, тематику, ссылки, афиши (OCR), а также любые уникальные “якоря” (например, номер концерта/серия лекций/название цикла).

LLM возвращает JSON:

- `match_event_id` (int или null)
- `confidence` (0..1)
- `reason_short` (строка для логов)

Политика:

- если `match_event_id=null` → создаём новый Event
- если `confidence < 0.6` → создаём новый Event (fail-safe против ложного мерджа)

Дополнительный guard для multi-hall: если в shortlist есть 2+ событий с одинаковыми `date/time/location_name`, то матчинг через LLM принимается только если `confidence >= 0.85`.

### Шаг 3. Мердж

#### 3.1. Жёсткие запреты (enforced)

Никогда не менять в существующем событии (если уже заполнено):

- `date`, `time`, `end_date`
- `location_name`, `location_address`

Если у события поле **пустое** — его можно заполнить (best-effort).

#### 3.2. Обогащение (LLM merge)

LLM получает:

- `event_before` (JSON, без возможности менять якорные поля)
- `candidate` (текст + извлечённые поля + OCR тексты + ссылки)
- `constraints` (строгие правила)

LLM возвращает JSON:

- `title` (опционально)
- `description` (обязательно)
- `ticket_link`, `ticket_price_min/max`, `ticket_status` (опционально)
- `added_facts[]` (короткие пункты, что добавили)
- `skipped_conflicts[]` (какие куски проигнорировали из-за противоречий)

**Важно:** если кандидат содержит противоречия по `date/time/location`, эти значения передаются в LLM как “conflicting_do_not_use”, чтобы модель не протащила их в описание.

#### 3.3. Картинки

- все `posters[]` добавляем в `EventPoster`, но только если `poster_hash` новый (или новый `phash`, если будет)
- если у кандидата нет новых постеров и текст не дал новых фактов → можно пропустить LLM merge (но источник всё равно сохраняем)

#### 3.4. Источники

Всегда создаём `event_source` для каждого уникального `source_url`.

### Шаг 4. Пересборка Telegraph и страниц

Smart Update должен приводить к тем же side-effects, что и стандартное добавление/обновление события:

- создание/обновление Telegraph страницы события;
- обновление month/week/weekend страниц (по существующим правилам проекта).

Иными словами: Smart Update не “правит поля и выходит”, а запускает стандартный пайплайн обновления страниц.

## 5. Каноничность источников (trust level)

Для конфликтов **не-якорных** фактов (например, цена/ссылка/статус билетов) используем `trust_level`:

- `high`: официальный сайт/тикет-система
- `medium`: официальный паблик/канал площадки
- `low`: агрегатор/городской паблик

Если конфликт:

- `high` побеждает `medium/low`
- `medium` побеждает `low`
- `low` никогда не перезаписывает данные, полученные из `high/medium` (может только добавить в “added_facts”, если это не конфликтует)

## 6. Наблюдаемость и алерты

Минимум логирования (в админ-чат и в логи):

- created / merged / skipped_same_source_url
- список ошибок (Kaggle download, LLM error, DB error)
- `added_facts` и `skipped_conflicts` (коротко, чтобы можно было глазами ревьюить качество)

## 7. Тест-план (реальный, под вашу модель работы)

### Preconditions

- свежий `db_prod_snapshot.sqlite` (локально)
- реальные секреты: `TG_SESSION`, `TG_API_ID`, `TG_API_HASH`, `GOOGLE_API_KEY`, `KAGGLE_*`

### Smoke

1) Запустить Telegram Monitoring вручную (`/tg -> Запустить мониторинг`)
2) Дождаться отчёта
3) Проверить:
   - появились новые события
   - у событий появились источники (несколько на одно событие допускается)
   - новые постеры сохранились как `EventPoster`

### Idempotency

Запустить мониторинг второй раз → не должно быть повторной обработки уже сканированных сообщений (и/или тех же `source_url`).

### Multi-event пост

Найти сообщение с >5 событий → убедиться, что все события прошли через импорт (сейчас это известная слабая точка).

### Merge quality (ручной контроль)

Выбрать событие, которое встречается в 2+ источниках → убедиться, что:

- якорные поля не поменялись
- описание стало богаче
- конфликтующие факты не протащились в карточку
