from __future__ import annotations

from collections import Counter
from datetime import datetime, timedelta
import html
import logging
import re
import time
from typing import Iterable, List, Tuple, Callable, Awaitable
import httpx

from sqlalchemy import select

from db import Database
from models import Event, normalize_topic_identifier

# Mapping of canonical topic -> set of synonyms (in lowercase)
TOPIC_SYNONYMS: dict[str, set[str]] = {
    "EXHIBITIONS": {"art", "–∏—Å–∫—É—Å—Å—Ç–≤–æ", "–≤—ã—Å—Ç–∞–≤–∫–∞", "–≤—ã—Å—Ç–∞–≤–∫–∏", "–≥–∞–ª–µ—Ä–µ—è"},
    "THEATRE": {"theatre", "—Ç–µ–∞—Ç—Ä", "—Å–ø–µ–∫—Ç–∞–∫–ª—å", "—Å–ø–µ–∫—Ç–∞–∫–ª–∏", "performance"},
    "THEATRE_CLASSIC": {
        "classic theatre",
        "–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Ç–µ–∞—Ç—Ä",
        "–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Å–ø–µ–∫—Ç–∞–∫–ª—å",
        "–¥—Ä–∞–º–∞",
        "–¥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ–∞—Ç—Ä",
    },
    "THEATRE_MODERN": {
        "modern theatre",
        "—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ç–µ–∞—Ç—Ä",
        "—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ø–µ–∫—Ç–∞–∫–ª–∏",
        "–º–æ–¥–µ—Ä–Ω",
        "experimental theatre",
        "—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π —Ç–µ–∞—Ç—Ä",
    },
    "CONCERTS": {"concert", "music", "–º—É–∑—ã–∫–∞", "–∫–æ–Ω—Ü–µ—Ä—Ç", "sound"},
    "MOVIES": {"cinema", "movie", "film", "–∫–∏–Ω–æ", "—Ñ–∏–ª—å–º"},
    "LECTURES": {
        "lecture",
        "lectures",
        "–ª–µ–∫—Ü–∏—è",
        "–ª–µ–∫—Ü–∏–∏",
        "–∏—Å—Ç–æ—Ä–∏—è",
        "–∏—Å—Ç–æ—Ä–∏—è —Ä–æ—Å—Å–∏–∏",
        "–∫–Ω–∏–≥–∏",
        "business",
        "–≤—Å—Ç—Ä–µ—á–∞",
    },
    "MASTERCLASS": {"masterclass", "–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å", "–≤–æ—Ä–∫—à–æ–ø"},
    "PARTIES": {"party", "–≤–µ—á–µ—Ä–∏–Ω–∫–∞", "–≤–µ—á–µ—Ä–∏–Ω–∫–∏"},
    "STANDUP": {"standup", "—Å—Ç–µ–Ω–¥–∞–ø", "—Å—Ç–µ–Ω–¥–∞–ø—ã", "–∫–æ–º–µ–¥–∏—è"},
    "QUIZ_GAMES": {"quiz", "–∫–≤–∏–∑", "–∫–≤–∏–∑—ã", "–∏–≥—Ä–∞", "–Ω–∞—Å—Ç–æ–ª–∫–∏"},
    "OPEN_AIR": {"open-air", "open air", "—Ñ–µ—Å—Ç–∏–≤–∞–ª—å", "—Ñ–µ—Å—Ç–∏–≤–∞–ª–∏", "openair"},
    "SCIENCE_POP": {"science", "science_pop", "–Ω–∞—É—á–ø–æ–ø", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"},
    "PSYCHOLOGY": {"–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è", "psychology", "mental health"},
    "HANDMADE": {
        "handmade",
        "hand-made",
        "—è—Ä–º–∞—Ä–∫–∞",
        "—è—Ä–º–∞—Ä–∫–∏",
        "–º–∞—Ä–∫–µ—Ç",
        "–º–∞—Ä–∫–µ—Ç—ã",
        "–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å",
        "–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã",
        "—Ö–µ–Ω–¥–º–µ–π–¥",
    },
    "NETWORKING": {
        "networking",
        "network",
        "–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥",
        "–Ω–µ—Ç–≤–æ—Ä–∫",
        "–∑–Ω–∞–∫–æ–º—Å—Ç–≤–∞",
        "–∫–∞—Ä—å–µ—Ä–∞",
        "–¥–µ–ª–æ–≤—ã–µ –≤—Å—Ç—Ä–µ—á–∏",
        "–±–∏–∑–Ω–µ—Å-–∑–∞–≤—Ç—Ä–∞–∫",
        "business breakfast",
        "–∫–∞—Ä—å–µ—Ä–Ω—ã–π –≤–µ—á–µ—Ä",
    },
    "ACTIVE": {
        "active",
        "sport",
        "sports",
        "—Å–ø–æ—Ä—Ç",
        "—Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ",
        "–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
        "–∞–∫—Ç–∏–≤–Ω—ã–π –æ—Ç–¥—ã—Ö",
        "—Ñ–∏—Ç–Ω–µ—Å",
        "–π–æ–≥–∞",
        "yoga",
    },
    "PERSONALITIES": {
        "personalities",
        "personality",
        "–ø–µ—Ä—Å–æ–Ω—ã",
        "–ª–∏—á–Ω–æ—Å—Ç–∏",
        "–≤—Å—Ç—Ä–µ—á–∞ —Å –∞–≤—Ç–æ—Ä–æ–º",
        "–≤—Å—Ç—Ä–µ—á–∞ —Å –≥–µ—Ä–æ–µ–º",
        "–≤—Å—Ç—Ä–µ—á–∞ —Å –∞—Ä—Ç–∏—Å—Ç–æ–º",
        "–∫–Ω–∏–∂–Ω—ã–π –∫–ª—É–±",
        "–∫–Ω–∏–∂–Ω—ã–µ –∫–ª—É–±—ã",
        "book club",
    },
    "KIDS_SCHOOL": {
        "kids",
        "kids_school",
        "–¥–µ—Ç–∏",
        "–¥–µ—Ç—è–º",
        "–¥–µ—Ç—Å–∫–∏–µ",
        "—à–∫–æ–ª–∞",
        "—à–∫–æ–ª—å–Ω–∏–∫–∏",
        "–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ",
    },
    "FAMILY": {
        "family",
        "—Å–µ–º—å—è",
        "—Å–µ–º–µ–π–Ω—ã–µ",
        "—Å–µ–º–µ–π–Ω—ã–π",
        "–¥–ª—è –≤—Å–µ–π —Å–µ–º—å–∏",
    },
    "URBANISM": {
        "urbanism",
        "—É—Ä–±–∞–Ω–∏—Å—Ç–∏–∫–∞",
        "—É—Ä–±–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–π",
        "—É—Ä–±–∞–Ω–∏—Å—Ç–∏–∫–µ",
    },
    "KRAEVEDENIE_KALININGRAD_OBLAST": {
        "–∫—Ä–∞–µ–≤–µ–¥–µ–Ω–∏–µ",
        "–∫—Ä–∞–µ–≤–µ–¥",
        "–∫—Ä–∞–µ–≤–µ–¥—á–µ—Å–∫–∏–π",
        "–∫—Ä–∞–µ–≤–µ–¥—á–µ—Å–∫–∏–µ",
        "–∫–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥",
        "kaliningrad",
        "–∫–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å",
        "–∫–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏",
        "–∫—ë–Ω–∏–≥—Å–±–µ—Ä–≥",
        "–∫–µ–Ω–∏–≥—Å–±–µ—Ä–≥",
        "k√∂nigsberg",
        "konigsberg",
        "koenigsberg",
        "kenigsberg",
        "kenig",
        "—è–Ω—Ç–∞—Ä–Ω—ã–π –∫—Ä–∞–π",
        "—è–Ω—Ç–∞—Ä–Ω–æ–≥–æ –∫—Ä–∞—è",
        "39 —Ä–µ–≥–∏–æ–Ω",
        "39-–π —Ä–µ–≥–∏–æ–Ω",
        "39–π —Ä–µ–≥–∏–æ–Ω",
        "39–π—Ä–µ–≥–∏–æ–Ω",
        "#–∫–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥",
    },
}

# Reverse lookup for quick normalization
_REVERSE_SYNONYMS = {
    syn.casefold(): canon
    for canon, syns in TOPIC_SYNONYMS.items()
    for syn in syns
}


MEETUPS_INTRO_FORBIDDEN_WORDINGS: tuple[str, ...] = (
    "¬´–ü–æ–≥—Ä—É–∑–∏—Ç–µ—Å—å¬ª",
    "¬´–Ω–µ —É–ø—É—Å—Ç–∏—Ç–µ —à–∞–Ω—Å¬ª",
    "–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Å ¬´–º–∏—Ä ‚Ä¶¬ª",
    "¬´–û—Ç–∫—Ä–æ–π—Ç–µ –¥–ª—è —Å–µ–±—è¬ª",
    "–ª—é–±—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è ¬´–≥–æ—Ä–∏–∑–æ–Ω—Ç–æ–≤¬ª",
)


def _format_forbidden_wordings(wordings: Iterable[str]) -> str:
    items = list(wordings)
    if not items:
        return ""
    if len(items) == 1:
        return items[0]
    if len(items) == 2:
        return f"{items[0]} –∏ {items[1]}"
    return ", ".join(items[:-1]) + f" –∏ {items[-1]}"


def parse_start_time(raw: str) -> tuple[int, int] | None:
    """–í–µ—Ä–Ω—ë—Ç (hh, mm) –∏–∑ —Å—Ç—Ä–æ–∫–∏ –≤—Ä–µ–º–µ–Ω–∏.

    –ë–µ—Ä—ë–º –ü–ï–†–í–û–ï –≤–∞–ª–∏–¥–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ ``:`` –∏ ``.``
    –∏ —Å–ª–æ–∂–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤—Ä–æ–¥–µ ``18:30‚Äì20:00`` –∏–ª–∏ ``18:30.15:30``. –ß–∞—Å—ã –∏
    –º–∏–Ω—É—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç—Å—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω—ã 0‚Äì23 –∏ 0‚Äì59 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ. –ï—Å–ª–∏ –≤—Ä–µ–º—è
    –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è ``None``.
    """

    match = re.search(r"\b(\d{1,2})[:\.](\d{2})\b", raw)
    if not match:
        return None

    hh = max(0, min(23, int(match.group(1))))
    mm = max(0, min(59, int(match.group(2))))
    return hh, mm


def _event_start_datetime(event: Event, digest_id: str | None = None) -> datetime:
    """Combine ``date`` and ``time`` fields of an event into a datetime."""

    cached = getattr(event, "_start_dt", None)
    if cached is not None:
        return cached

    day = datetime.strptime(event.date, "%Y-%m-%d")
    raw = event.time or ""
    parsed = parse_start_time(raw)

    if parsed is None:
        logging.warning(
            "digest.time.parse digest_id=%s event_id=%s title=%r time_raw=%r parsed=null reason_if_null=no_match",
            digest_id,
            event.id,
            event.title,
            raw,
        )
        dt = day
    else:
        hh, mm = parsed
        logging.info(
            "digest.time.parse digest_id=%s event_id=%s title=%r time_raw=%r parsed=%02d:%02d",
            digest_id,
            event.id,
            event.title,
            raw,
            hh,
            mm,
        )
        dt = day.replace(hour=hh, minute=mm)

    setattr(event, "_start_dt", dt)
    return dt


async def _build_digest_candidates(
    event_type: str | None,
    db: Database,
    now: datetime,
    digest_id: str | None = None,
    *,
    topic_identifier: str | None = None,
    topic_identifiers: Iterable[str] | None = None,
) -> Tuple[List[Event], int]:
    """Select events within the digest window with optional filters.

    Parameters
    ----------
    event_type:
        ``Event.event_type`` value to filter by. When ``None`` the filter is
        omitted which allows combining with topic-based selection.
    topic_identifier:
        Canonical topic identifier (e.g. ``"PSYCHOLOGY"``). When provided the
        resulting events must contain the topic after normalization.
    """

    start_date = now.date().isoformat()
    end_date = (now + timedelta(days=14)).date().isoformat()

    async with db.get_session() as session:
        query = (
            select(Event)
            .where(
                Event.date >= start_date,
                Event.date <= end_date,
            )
            .order_by(Event.date, Event.time)
        )
        if event_type is not None:
            query = query.where(Event.event_type == event_type)
        res = await session.execute(query)
        events = list(res.scalars().all())

    topic_filters: set[str] = set()
    if topic_identifier:
        normalized_topic = normalize_topic_identifier(topic_identifier) or topic_identifier
        topic_filters.add(normalized_topic)
    if topic_identifiers:
        for raw in topic_identifiers:
            if not raw:
                continue
            canonical = normalize_topic_identifier(raw) or raw
            topic_filters.add(canonical)

    if topic_filters:
        filtered: List[Event] = []
        for event in events:
            topics = set(normalize_topics(getattr(event, "topics", [])))
            if topics.intersection(topic_filters):
                filtered.append(event)
        events = filtered

    cutoff = now + timedelta(hours=2)
    events = [e for e in events if _event_start_datetime(e, digest_id) >= cutoff]
    events.sort(key=lambda e: _event_start_datetime(e, digest_id))

    horizon = 7
    end_7 = now + timedelta(days=7)
    result: List[Event] = []
    for ev in events:
        if _event_start_datetime(ev, digest_id) > end_7:
            continue
        if pick_display_link(ev) is None:
            logging.info(
                "digest.skip.no_link event_id=%s title=%r event_type=%s",
                getattr(ev, "id", None),
                ev.title,
                event_type,
            )
            continue
        result.append(ev)
        if len(result) == 9:
            break

    if len(result) < 9:
        horizon = 14
        end_14 = now + timedelta(days=14)
        result = []
        for ev in events:
            if _event_start_datetime(ev, digest_id) > end_14:
                continue
            if pick_display_link(ev) is None:
                logging.info(
                    "digest.skip.no_link event_id=%s title=%r event_type=%s",
                    getattr(ev, "id", None),
                    ev.title,
                    event_type,
                )
                continue
            result.append(ev)
            if len(result) == 9:
                break

    return result, horizon


async def build_lectures_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select lecture events for the digest."""

    return await _build_digest_candidates("–ª–µ–∫—Ü–∏—è", db, now, digest_id)


async def build_masterclasses_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select master-class events for the digest."""

    return await _build_digest_candidates("–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å", db, now, digest_id)


async def build_psychology_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select psychology-tagged events for the digest."""

    return await _build_digest_candidates(
        None, db, now, digest_id, topic_identifier="PSYCHOLOGY"
    )


async def build_science_pop_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select science-pop events for the digest."""

    return await _build_digest_candidates(
        None, db, now, digest_id, topic_identifier="SCIENCE_POP"
    )


async def build_kraevedenie_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select Kaliningrad regional heritage events for the digest."""

    return await _build_digest_candidates(
        None,
        db,
        now,
        digest_id,
        topic_identifier="KRAEVEDENIE_KALININGRAD_OBLAST",
    )


async def build_networking_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select networking-focused events for the digest."""

    return await _build_digest_candidates(
        None, db, now, digest_id, topic_identifier="NETWORKING"
    )


async def build_entertainment_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select stand-up, quiz, party and open-air events for the digest."""

    return await _build_digest_candidates(
        None,
        db,
        now,
        digest_id,
        topic_identifiers=("STANDUP", "QUIZ_GAMES", "PARTIES", "OPEN_AIR"),
    )


async def build_markets_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select handmade market events for the digest."""

    return await _build_digest_candidates(
        None, db, now, digest_id, topic_identifier="HANDMADE"
    )


async def build_theatre_classic_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select classic theatre performances for the digest."""

    return await _build_digest_candidates(
        "—Å–ø–µ–∫—Ç–∞–∫–ª—å",
        db,
        now,
        digest_id,
        topic_identifier="THEATRE_CLASSIC",
    )


async def build_theatre_modern_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select modern theatre performances for the digest."""

    return await _build_digest_candidates(
        "—Å–ø–µ–∫—Ç–∞–∫–ª—å",
        db,
        now,
        digest_id,
        topic_identifier="THEATRE_MODERN",
    )


async def build_meetups_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select meetups and club events for the digest."""

    return await _build_digest_candidates(
        None, db, now, digest_id, topic_identifier="PERSONALITIES"
    )


async def build_movies_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select movie screening events for the digest."""

    return await _build_digest_candidates("–∫–∏–Ω–æ–ø–æ–∫–∞–∑", db, now, digest_id)


def _event_end_date(event: Event) -> datetime | None:
    """Return ``datetime`` for ``event.end_date`` if possible."""

    raw = getattr(event, "end_date", None)
    if not raw:
        return None
    try:
        return datetime.strptime(raw, "%Y-%m-%d")
    except ValueError:
        logging.warning(
            "digest.end_date.parse event_id=%s title=%r end_date_raw=%r parsed=null",  # noqa: G003
            getattr(event, "id", None),
            event.title,
            raw,
        )
        return None


async def build_exhibitions_digest_candidates(
    db: Database, now: datetime, digest_id: str | None = None
) -> Tuple[List[Event], int]:
    """Select exhibition events for the digest."""

    today_iso = now.date().isoformat()

    async with db.get_session() as session:
        res = await session.execute(
            select(Event)
            .where(
                Event.event_type == "–≤—ã—Å—Ç–∞–≤–∫–∞",
                Event.end_date.is_not(None),
                Event.end_date >= today_iso,
            )
            .order_by(Event.date, Event.time)
        )
        events = list(res.scalars().all())

    cutoff = now + timedelta(hours=2)
    filtered: List[Event] = []
    for ev in events:
        start_dt = _event_start_datetime(ev, digest_id)
        if start_dt >= now and start_dt < cutoff:
            continue
        filtered.append(ev)

    events = filtered
    events.sort(
        key=lambda e: (
            _event_end_date(e) or datetime.max,
            _event_start_datetime(e, digest_id),
        )
    )

    def _within_horizon(ev: Event, days: int) -> bool:
        end_dt = _event_end_date(ev)
        if end_dt is None:
            return False
        return end_dt.date() <= (now + timedelta(days=days)).date()

    horizon = 7
    result: List[Event] = []
    for ev in events:
        if not _within_horizon(ev, horizon):
            continue
        if pick_display_link(ev) is None:
            logging.info(
                "digest.skip.no_link event_id=%s title=%r event_type=%s",
                getattr(ev, "id", None),
                ev.title,
                "–≤—ã—Å—Ç–∞–≤–∫–∞",
            )
            continue
        result.append(ev)
        if len(result) == 9:
            break

    if len(result) < 9:
        horizon = 14
        result = []
        for ev in events:
            if not _within_horizon(ev, horizon):
                continue
            if pick_display_link(ev) is None:
                logging.info(
                    "digest.skip.no_link event_id=%s title=%r event_type=%s",
                    getattr(ev, "id", None),
                    ev.title,
                    "–≤—ã—Å—Ç–∞–≤–∫–∞",
                )
                continue
            result.append(ev)
            if len(result) == 9:
                break

    return result, horizon


def normalize_topics(topics: Iterable[str]) -> List[str]:
    """Normalize topics using the synonym map.

    The function lowercases input topics, maps known synonyms to their
    canonical form, removes duplicates and returns a sorted list.
    """

    normalized: list[str] = []
    for topic in topics:
        canonical = normalize_topic_identifier(topic)
        if canonical:
            normalized.append(canonical)
            continue
        if not isinstance(topic, str):
            continue
        cleaned = topic.strip()
        if not cleaned:
            continue
        mapped = _REVERSE_SYNONYMS.get(cleaned.casefold())
        if mapped:
            normalized.append(mapped)
        else:
            normalized.append(cleaned)
    return sorted(set(normalized))


def aggregate_digest_topics(events: Iterable[Event]) -> List[str]:
    """Aggregate topics from events and return top-3 by frequency.

    Events are expected to have ``topics`` attribute containing a list of
    strings. Unknown topics are included as-is after normalization.
    """

    counter: Counter[str] = Counter()
    for ev in events:
        for topic in normalize_topics(getattr(ev, "topics", [])):
            counter[topic] += 1

    if not counter:
        return []

    ranked = sorted(counter.items(), key=lambda x: (-x[1], x[0]))
    return [t for t, _ in ranked[:3]]


async def extract_catbox_covers_from_telegraph(
    page_url: str, *, event_id: str | int | None = None
) -> List[str]:
    """Extract ``files.catbox.moe`` image URLs from a Telegraph page.

    Parameters
    ----------
    page_url:
        URL of the Telegraph page.

    Returns
    -------
    list[str]
        List of URLs in order of appearance. Only ``files.catbox.moe`` links
        with typical image extensions are returned. No HEAD requests are
        performed ‚Äì validation is based solely on the file extension.
    """

    import uuid

    run_id = uuid.uuid4().hex
    start = time.monotonic()
    logging.info(
        "digest.cover.fetch.start event_id=%s run_id=%s telegraph_url=%s",
        event_id,
        run_id,
        page_url,
    )
    try:
        async with httpx.AsyncClient() as client:
            resp = await client.get(page_url)
    except Exception:
        logging.info(
            "digest.cover.missing event_id=%s run_id=%s reason=network_error",
            event_id,
            run_id,
        )
        return []
    took_ms = int((time.monotonic() - start) * 1000)
    logging.info(
        "digest.cover.fetch.html.ok event_id=%s run_id=%s bytes=%s took_ms=%s",
        event_id,
        run_id,
        len(resp.content or b""),
        took_ms,
    )
    html = resp.text
    pattern = re.compile(
        r'(?:src|href)="(https://files\.catbox\.moe/[^"]+\.(?:jpg|jpeg|png|webp|gif))"',
        re.IGNORECASE,
    )
    matches = pattern.findall(html)
    results: List[str] = []
    for url in matches:
        ext = url.rsplit(".", 1)[-1].lower()
        logging.info(
            "digest.cover.candidate event_id=%s url=%s ext=%s",
            event_id,
            url,
            ext,
        )
        results.append(url)

    if results:
        logging.info(
            "digest.cover.accepted event_id=%s url=%s",
            event_id,
            results[0],
        )
    else:
        logging.info(
            "digest.cover.missing event_id=%s reason=no_catbox_in_html",
            event_id,
        )

    return results
 

async def compose_digest_intro_via_4o(
    n: int, horizon_days: int, titles: List[str], *, event_noun: str = "–ª–µ–∫—Ü–∏–π"
) -> str:
    """Generate an intro phrase for the digest via model 4o.

    The helper imports :func:`main.ask_4o` lazily to avoid circular imports.
    Request and response metrics are logged with ``digest.intro.llm.*`` tags.
    """

    from main import ask_4o, FOUR_O_TIMEOUT  # local import to avoid cycle
    import uuid

    run_id = uuid.uuid4().hex
    horizon_word = "–Ω–µ–¥–µ–ª—é" if horizon_days == 7 else "–¥–≤–µ –Ω–µ–¥–µ–ª–∏"
    titles_str = "; ".join(titles[:9])
    prompt = (
        "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (‚â§140 —Å–∏–º–≤–æ–ª–æ–≤) –≤–æ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ –∫ –¥–∞–π–¥–∂–µ—Å—Ç—É"
        f" –∏–∑ {n} {event_noun} –Ω–∞ –±–ª–∏–∂–∞–π—à—É—é {horizon_word} –±–µ–∑ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º—É: "
        f"'N {event_noun} –Ω–∞ –±–ª–∏–∂–∞–π—à—É—é ... ‚Äî –æ—Ç X –¥–æ Y.' X –∏ Y –≤—ã–±–µ—Ä–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏–π –Ω–∏–∂–µ."
    )
    if titles_str:
        prompt += f" –ù–∞–∑–≤–∞–Ω–∏—è: {titles_str}."

    logging.info(
        "digest.intro.llm.request run_id=%s n=%s horizon=%s titles_count=%s prompt_len=%s",
        run_id,
        n,
        horizon_days,
        len(titles),
        len(prompt),
    )

    start = time.monotonic()
    try:
        text = await ask_4o(prompt, max_tokens=120)
    except Exception:
        took_ms = int((time.monotonic() - start) * 1000)
        logging.info(
            "digest.intro.llm.response run_id=%s ok=error text_len=0 took_ms=%s",
            run_id,
            took_ms,
        )
        raise

    took_ms = int((time.monotonic() - start) * 1000)
    text = text.strip()
    m = re.search(r"–æ—Ç\s+([^\s].*?)\s+–¥–æ\s+([^\.]+)", text, re.IGNORECASE)
    x = m.group(1).strip() if m else ""
    y = m.group(2).strip() if m else ""
    logging.info(
        "digest.intro.llm.response run_id=%s ok=ok text_len=%s took_ms=%s x=%s y=%s",
        run_id,
        len(text),
        took_ms,
        x,
        y,
    )
    return text


def _detect_meetup_formats(event: Event, normalized: dict[str, str]) -> List[str]:
    """Return a list of human-friendly meetup formats derived from text."""

    haystack_parts = [
        normalized.get("title_clean") or event.title,
        event.description or "",
        event.event_type or "",
    ]
    haystack = " ".join(haystack_parts).lower()

    formats: List[str] = []

    def add_format(condition: bool, label: str) -> None:
        if condition and label not in formats:
            formats.append(label)

    add_format("–∫–ª—É–±" in haystack or "club" in haystack, "–∫–ª—É–±")
    add_format(
        re.search(r"\b–≤—Å—Ç—Ä–µ—á", haystack) is not None
        or "meetup" in haystack
        or "meeting" in haystack,
        "–≤—Å—Ç—Ä–µ—á–∞",
    )
    add_format(
        ("—Ç–≤–æ—Ä—á–µ—Å" in haystack and "–≤–µ—á–µ—Ä" in haystack)
        or "creative evening" in haystack,
        "—Ç–≤–æ—Ä—á–µ—Å–∫–∏–π –≤–µ—á–µ—Ä",
    )
    add_format("–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω" in haystack or "network" in haystack, "–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥")
    add_format("q&a" in haystack or "q & a" in haystack, "Q&A")
    add_format("–¥–∏—Å–∫—É—Å" in haystack or "discussion" in haystack, "–¥–∏—Å–∫—É—Å—Å–∏—è")
    add_format("—Ñ–æ—Ä—É–º" in haystack or "forum" in haystack, "—Ñ–æ—Ä—É–º")

    return formats


_MEETUPS_TONE_KEYWORDS: dict[str, tuple[str, ...]] = {
    "–∏–Ω—Ç—Ä–∏–≥–∞": ("—Å–µ–∫—Ä–µ—Ç", "–∑–∞–∫—É–ª–∏—Å—å–µ", "–≤–ø–µ—Ä–≤—ã–µ"),
    "–ø—Ä–æ—Å—Ç–æ—Ç–∞": ("–æ—Ç–∫—Ä—ã—Ç–∞—è –≤—Å—Ç—Ä–µ—á–∞", "–±–µ–∑ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏"),
    "–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ": ("—É–∑–Ω–∞–µ—Ç–µ", "—Ä–µ–¥–∫–∏–µ —Ñ–∞–∫—Ç—ã"),
}

_MEETUPS_TONE_PRIORITY: dict[str, int] = {
    "–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ": 0,
    "–∏–Ω—Ç—Ä–∏–≥–∞": 1,
    "–ø—Ä–æ—Å—Ç–æ—Ç–∞": 2,
}

_DEFAULT_MEETUPS_TONE_HINT = "–ø—Ä–æ—Å—Ç–æ—Ç–∞+–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ"


def _update_meetups_tone(counter: Counter[str], text: str) -> None:
    """Increment tone counters based on keywords found in ``text``."""

    haystack = text.casefold()
    for tone, keywords in _MEETUPS_TONE_KEYWORDS.items():
        if any(keyword in haystack for keyword in keywords):
            counter[tone] += 1


def _select_meetups_tone_hint(counter: Counter[str]) -> str:
    """Return combined tone hint from accumulated keyword ``counter``."""

    if not counter:
        return _DEFAULT_MEETUPS_TONE_HINT

    sorted_items = sorted(
        counter.items(),
        key=lambda item: (
            -item[1],
            _MEETUPS_TONE_PRIORITY.get(item[0], len(_MEETUPS_TONE_PRIORITY)),
        ),
    )

    top_tones = [tone for tone, count in sorted_items if count > 0][:2]

    if not top_tones:
        return _DEFAULT_MEETUPS_TONE_HINT

    return "+".join(top_tones)


async def compose_masterclasses_intro_via_4o(
    n: int, horizon_days: int, masterclasses: List[dict[str, str]]
) -> str:
    """Generate intro phrase for master-class digest via model 4o."""

    from main import ask_4o  # local import to avoid cycle
    import json
    import uuid

    run_id = uuid.uuid4().hex
    horizon_word = "–Ω–µ–¥–µ–ª—é" if horizon_days == 7 else "–¥–≤–µ –Ω–µ–¥–µ–ª–∏"
    data_json = json.dumps(masterclasses[:9], ensure_ascii=False)
    prompt = (
        "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Ç–µ–ª–µ–≥—Ä–∞–º-–¥–∞–π–¥–∂–µ—Å—Ç—É –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π."  # context
        f" –°–æ—Ö—Ä–∞–Ω–∏ –∫–∞—Ä–∫–∞—Å ¬´{n} –º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –±–ª–∏–∂–∞–π—à—É—é {horizon_word} ‚Äî ‚Ä¶¬ª"
        " –∏ –æ–±—â–∏–π —Ç–æ–Ω –ª–µ–∫—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –±–µ–∑ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π."
        " –¢–µ–∫—Å—Ç —Å–¥–µ–ª–∞–π –¥–∏–Ω–∞–º–∏—á–Ω—ã–º –∏ –∫–æ—Ä–æ—Ç–∫–∏–º: 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ ~200 —Å–∏–º–≤–æ–ª–æ–≤,"
        " –ø–æ–º–Ω–∏, —á—Ç–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–µ–∂–µ–ª–∞—Ç–µ–ª–µ–Ω."
        " –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏."
        " –ü–æ—Å–ª–µ —Ç–∏—Ä–µ –ø–µ—Ä–µ—á–∏—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏–π, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è"
        " —É–ø–æ–º—è–Ω—É—Ç—å –∫–∞–∂–¥–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–∏ —Ä–∞–∑–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä,"
        " ¬´—Ä–∏—Å–æ–≤–∞–Ω–∏–µ, —Ä–∞–±–æ—Ç–∞ —Å –≥–æ–ª–æ—Å–æ–º, —Å–æ–∑–¥–∞–Ω–∏–µ –¥—É—Ö–æ–≤¬ª)."
        " –û–ø–∏—Ä–∞–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏–∑ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –Ω–∏–∂–µ, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤."
        " –ï—Å–ª–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω –≤–æ–∑—Ä–∞—Å—Ç –∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç –≥—Ä—É–ø–ø—ã, —É–ø–æ–º—è–Ω–∏ —ç—Ç–æ."
        " –î–∞–Ω–Ω—ã–µ –æ –º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å–∞—Ö –≤ JSON (title ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ,"
        f" description ‚Äî –ø–æ–ª–Ω–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è): {data_json}"
    )

    logging.info(
        "digest.intro.llm.request run_id=%s kind=masterclass n=%s horizon=%s items_count=%s prompt_len=%s",
        run_id,
        n,
        horizon_days,
        len(masterclasses),
        len(prompt),
    )

    start = time.monotonic()
    try:
        text = await ask_4o(prompt, max_tokens=160)
    except Exception:
        took_ms = int((time.monotonic() - start) * 1000)
        logging.info(
            "digest.intro.llm.response run_id=%s kind=masterclass ok=error text_len=0 took_ms=%s",
            run_id,
            took_ms,
        )
        raise

    took_ms = int((time.monotonic() - start) * 1000)
    text = text.strip()
    logging.info(
        "digest.intro.llm.response run_id=%s kind=masterclass ok=ok text_len=%s took_ms=%s",
        run_id,
        len(text),
        took_ms,
    )
    return text


async def compose_exhibitions_intro_via_4o(
    n: int, horizon_days: int, exhibitions: List[dict[str, object]]
) -> str:
    """Generate intro phrase for exhibition digest via model 4o."""

    from main import ask_4o  # local import to avoid cycle
    import json
    import uuid

    run_id = uuid.uuid4().hex
    horizon_word = "–Ω–µ–¥–µ–ª—é" if horizon_days == 7 else "–¥–≤–µ –Ω–µ–¥–µ–ª–∏"
    data_json = json.dumps(exhibitions[:9], ensure_ascii=False)
    prompt = (
        "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Ç–µ–ª–µ–≥—Ä–∞–º-–¥–∞–π–¥–∂–µ—Å—Ç—É –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π."
        f" –ù–∞—á–Ω–∏ –∏–Ω—Ç—Ä–æ —Ç–∞–∫: ¬´–ù–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–µ, –≤ –±–ª–∏–∂–∞–π—à–∏–µ {horizon_word} –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è {n} –≤—ã—Å—Ç–∞–≤–æ–∫ ‚Äî ‚Ä¶¬ª."
        " –í—Å–µ–≥–æ –æ—Å—Ç–∞–≤—å 1‚Äì2 —Å–≤—è–∑–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ ~200 —Å–∏–º–≤–æ–ª–æ–≤ –±–µ–∑ —Å–ø–∏—Å–∫–æ–≤, –¥–µ–ª–∞—è –∏—Ö –¥–∏–Ω–∞–º–∏—á–Ω—ã–º–∏."
        " –ò—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏."
        " –°–¥–µ–ª–∞–π –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —Å–∫–æ—Ä–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–º–∞—Ö –≤—ã—Å—Ç–∞–≤–æ–∫ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—è–º."
        " –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ –ø–æ–ª—è description –∏ date_range –∫–∞–∂–¥–æ–π –≤—ã—Å—Ç–∞–≤–∫–∏ –∏ –Ω–∞–∑—ã–≤–∞–π –¥–∞—Ç—ã –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–æ –ø–æ–ª—é end."
        " –û–ø–∏—Ä–∞–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Ñ–∞–∫—Ç—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π –¥–µ—Ç–∞–ª–∏."
        " –î–∞–Ω–Ω—ã–µ –æ –≤—ã—Å—Ç–∞–≤–∫–∞—Ö –≤ JSON (title ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ,"
        ' description ‚Äî –ø–æ–ª–Ω–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è, date_range ‚Äî {"start": "YYYY-MM-DD",'
        ' "end": "YYYY-MM-DD"}): '
        f"{data_json}"
    )

    logging.info(
        "digest.intro.llm.request run_id=%s kind=exhibition n=%s horizon=%s items_count=%s prompt_len=%s",
        run_id,
        n,
        horizon_days,
        len(exhibitions),
        len(prompt),
    )

    start = time.monotonic()
    try:
        text = await ask_4o(prompt, max_tokens=160)
    except Exception:
        took_ms = int((time.monotonic() - start) * 1000)
        logging.info(
            "digest.intro.llm.response run_id=%s kind=exhibition ok=error text_len=0 took_ms=%s",
            run_id,
            took_ms,
        )
        raise

    took_ms = int((time.monotonic() - start) * 1000)
    text = text.strip()
    logging.info(
        "digest.intro.llm.response run_id=%s kind=exhibition ok=ok text_len=%s took_ms=%s",
        run_id,
        len(text),
        took_ms,
    )
    return text


async def compose_psychology_intro_via_4o(
    n: int, horizon_days: int, events: List[dict[str, object]]
) -> str:
    """Generate intro phrase for psychology digest via model 4o."""

    from main import ask_4o  # local import to avoid cycle
    import json
    import uuid

    run_id = uuid.uuid4().hex
    horizon_word = "–Ω–µ–¥–µ–ª—é" if horizon_days == 7 else "–¥–≤–µ –Ω–µ–¥–µ–ª–∏"
    data_json = json.dumps(events[:9], ensure_ascii=False)
    prompt = (
        "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Ç–µ–ª–µ–≥—Ä–∞–º-–¥–∞–π–¥–∂–µ—Å—Ç—É –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π."  # context
        f" –°–æ—Ö—Ä–∞–Ω–∏ –∫–∞—Ä–∫–∞—Å ¬´{n} –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π –Ω–∞ –±–ª–∏–∂–∞–π—à—É—é {horizon_word} ‚Äî ‚Ä¶¬ª."
        " –û—Ç–≤–µ—Ç —Å–¥–µ–ª–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ ~200 —Å–∏–º–≤–æ–ª–æ–≤ –±–µ–∑ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π."
        " –î–æ–±–∞–≤—å 1‚Äì2 –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —ç–º–æ–¥–∑–∏."
        " –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ –ø–æ–ª—è topics –∏ description, –∫—Ä–∞—Ç–∫–æ –æ–±—ä–µ–¥–∏–Ω—è—è –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã"
        " (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –∑–¥–æ—Ä–æ–≤—å–µ, –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ—Å—Ç—å, –ø–æ–¥–¥–µ—Ä–∂–∫–∞)."
        " –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON."
        " –î–∞–Ω–Ω—ã–µ –æ —Å–æ–±—ã—Ç–∏—è—Ö –≤ JSON —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π"
        ' {"title": "‚Ä¶", "description": "‚Ä¶", "topics": ["PSYCHOLOGY", ‚Ä¶]}: '
        f"{data_json}"
    )

    logging.info(
        "digest.intro.llm.request run_id=%s kind=psychology n=%s horizon=%s items_count=%s prompt_len=%s",
        run_id,
        n,
        horizon_days,
        len(events),
        len(prompt),
    )

    start = time.monotonic()
    try:
        text = await ask_4o(prompt, max_tokens=160)
    except Exception:
        took_ms = int((time.monotonic() - start) * 1000)
        logging.info(
            "digest.intro.llm.response run_id=%s kind=psychology ok=error text_len=0 took_ms=%s",
            run_id,
            took_ms,
        )
        raise

    took_ms = int((time.monotonic() - start) * 1000)
    text = text.strip()
    logging.info(
        "digest.intro.llm.response run_id=%s kind=psychology ok=ok text_len=%s took_ms=%s",
        run_id,
        len(text),
        took_ms,
    )
    return text


async def compose_meetups_intro_via_4o(
    n: int,
    horizon_days: int,
    meetups: List[dict[str, object]],
    tone_hint: str | None = None,
) -> str:
    """Generate intro phrase for meetup digest via model 4o."""

    from main import ask_4o  # local import to avoid cycle
    import json
    import uuid

    run_id = uuid.uuid4().hex
    horizon_word = "–Ω–µ–¥–µ–ª—é" if horizon_days == 7 else "–¥–≤–µ –Ω–µ–¥–µ–ª–∏"
    data_json = json.dumps(meetups[:9], ensure_ascii=False)
    has_club = any(
        "–∫–ª—É–±" in [fmt.casefold() for fmt in item.get("formats", [])]
        for item in meetups
    )
    has_club_flag = "true" if has_club else "false"

    hint = tone_hint or _DEFAULT_MEETUPS_TONE_HINT
    tone_tokens = [token for token in (hint or "").split("+") if token]
    if tone_tokens:
        formatted_tokens = [tone_tokens[0].capitalize()]
        formatted_tokens.extend(token.lower() for token in tone_tokens[1:])
        tone_pattern = " + ".join(formatted_tokens)
        tone_instruction = (
            f" –ò—Å–ø–æ–ª—å–∑—É–π –ø–∞—Ç—Ç–µ—Ä–Ω ¬´{tone_pattern}¬ª, –∏–∑–±–µ–≥–∞–π –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–æ–Ω–æ–≤."
        )
    else:
        tone_instruction = ""

    forbidden_guidance = _format_forbidden_wordings(
        MEETUPS_INTRO_FORBIDDEN_WORDINGS
    )

    prompt = (
        "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Ç–µ–ª–µ–≥—Ä–∞–º-–¥–∞–π–¥–∂–µ—Å—Ç—É –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π."
        f" –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∂–∏–≤–æ–µ –∏–Ω—Ç—Ä–æ –Ω–∞ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ ~200 —Å–∏–º–≤–æ–ª–æ–≤ –∫ –ø–æ–¥–±–æ—Ä–∫–µ –∏–∑ {n} –≤—Å—Ç—Ä–µ—á"
        f" –∏ –∫–ª—É–±–æ–≤ –Ω–∞ –±–ª–∏–∂–∞–π—à—É—é {horizon_word}."
        " –î–æ–±–∞–≤—å 1‚Äì2 —É–º–µ—Å—Ç–Ω—ã—Ö —ç–º–æ–¥–∑–∏, –∏–∑–±–µ–≥–∞–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π –∏ —Å–ø–∏—Å–∫–æ–≤."
        " –û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –ø–æ–ª—è title, description, event_type –∏ formats –∫–∞–∂–¥–æ–≥–æ —Å–æ–±—ã—Ç–∏—è,"
        " —á—Ç–æ–±—ã –≤—ã–¥–µ–ª–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏ —Ñ–æ—Ä–º–∞—Ç—ã."
        f" –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: has_club={has_club_flag}."
        f"{tone_instruction}"
        f" –ò–∑–±–µ–≥–∞–π —Ä–µ–∫–ª–∞–º–Ω—ã—Ö –∫–ª–∏—à–µ: –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π {forbidden_guidance}."
        " –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–æ–¥—á–µ—Ä–∫–Ω–∏ –∂–∏–≤–æ–µ –æ–±—â–µ–Ω–∏–µ: –∑–Ω–∞–∫–æ–º—Å—Ç–≤–æ —Å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º–∏ –ª—é–¥—å–º–∏, –∂–∏–≤–æ–µ Q&A"
        " –∏ –Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥."
        " –ï—Å–ª–∏ has_club=false, —Å–¥–µ–ª–∞–π –Ω–∞ —ç—Ç–æ–º –∞–∫—Ü–µ–Ω—Ç –µ—â—ë –∑–∞–º–µ—Ç–Ω–µ–µ."
        " –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON –Ω–∏–∂–µ."
        f" –î–∞–Ω–Ω—ã–µ –æ –≤—Å—Ç—Ä–µ—á–∞—Ö –≤ JSON: {data_json}"
    )

    logging.info(
        "digest.intro.llm.request run_id=%s kind=meetups n=%s horizon=%s items_count=%s prompt_len=%s has_club=%s tone_hint=%s",
        run_id,
        n,
        horizon_days,
        len(meetups),
        len(prompt),
        int(has_club),
        hint,
    )

    start = time.monotonic()
    try:
        text = await ask_4o(prompt, max_tokens=160)
    except Exception:
        took_ms = int((time.monotonic() - start) * 1000)
        logging.info(
            "digest.intro.llm.response run_id=%s kind=meetups ok=error text_len=0 took_ms=%s",
            run_id,
            took_ms,
        )
        raise

    took_ms = int((time.monotonic() - start) * 1000)
    text = text.strip()
    logging.info(
        "digest.intro.llm.response run_id=%s kind=meetups ok=ok text_len=%s took_ms=%s",
        run_id,
        len(text),
        took_ms,
    )
    return text


def _normalize_exhibition_title(title: str) -> dict[str, str]:
    """Return exhibition title without lecture-specific formatting."""

    emoji, rest = _split_leading_emoji(title)
    cleaned = re.sub(r"\s+", " ", rest).strip()
    if not cleaned:
        cleaned = rest.strip() or title.strip()
    return {"emoji": emoji, "title_clean": cleaned}


def _align_event_contexts(
    events: Iterable[Any] | None, expected_len: int
) -> List[Any | None]:
    """Return a list of ``events`` padded/truncated to ``expected_len``."""

    if expected_len <= 0:
        return []

    if events is None:
        return [None] * expected_len

    seq = list(events)
    if len(seq) < expected_len:
        seq.extend([None] * (expected_len - len(seq)))
    else:
        seq = seq[:expected_len]
    return seq


def _prepare_meetup_context(event: Any | None) -> dict[str, str]:
    """Extract context fields from ``event`` for meetup normalization."""

    if event is None:
        return {"event_type": "", "description": ""}

    event_type = getattr(event, "event_type", "") or ""
    description = getattr(event, "description", "") or ""
    return {
        "event_type": str(event_type),
        "description": re.sub(r"\s+", " ", str(description)).strip(),
    }


def _truncate_context(text: str, *, limit: int = 220) -> str:
    """Trim ``text`` to ``limit`` characters while keeping whole words."""

    if len(text) <= limit:
        return text

    truncated = text[: limit + 1].rstrip()
    if " " in truncated:
        truncated = truncated.rsplit(" ", 1)[0]
    if not truncated:
        truncated = text[:limit].rstrip()
    return truncated + "‚Ä¶"


def _should_add_meetup_exhibition_clarifier(
    event: Any | None, *, title: str
) -> bool:
    """Return ``True`` when meetup title should mention exhibition context."""

    lower_title = title.casefold()
    if "—Ç–≤–æ—Ä—á–µ—Å–∫–∞—è –≤—Å—Ç—Ä–µ—á–∞ –∏ –æ—Ç–∫—Ä—ã—Ç–∏–µ –≤—ã—Å—Ç–∞–≤–∫–∏" in lower_title:
        return False
    if "–≤—ã—Å—Ç–∞–≤" in lower_title:
        return False

    if event is None:
        return False

    event_type = (getattr(event, "event_type", "") or "").casefold()
    description = (getattr(event, "description", "") or "").casefold()

    if "–≤—ã—Å—Ç–∞–≤" in event_type:
        return True
    if "–≤—ã—Å—Ç–∞–≤" in description:
        return True
    return False


def _apply_meetup_postprocessing(title: str, event: Any | None) -> str:
    """Append clarifier for meetup events tied to exhibitions when needed."""

    if _should_add_meetup_exhibition_clarifier(event, title=title):
        return f"{title} ‚Äî —Ç–≤–æ—Ä—á–µ—Å–∫–∞—è –≤—Å—Ç—Ä–µ—á–∞ –∏ –æ—Ç–∫—Ä—ã—Ç–∏–µ –≤—ã—Å—Ç–∞–≤–∫–∏"
    return title


async def normalize_titles_via_4o(
    titles: List[str], *, event_kind: str = "lecture", events: Iterable[Any] | None = None
) -> List[dict[str, str]]:
    """Normalize event titles using model 4o with regex fallback."""

    if event_kind == "exhibition":
        return [_normalize_exhibition_title(t) for t in titles]

    events_list = _align_event_contexts(events, len(titles))

    if event_kind == "meetups":
        from main import ask_4o  # local import to avoid a cycle
        import json

        contexts: List[str] = []
        for idx, (title, event) in enumerate(zip(titles, events_list), start=1):
            pieces = [f"–ù–∞–∑–≤–∞–Ω–∏–µ: ¬´{title}¬ª"]
            ctx = _prepare_meetup_context(event)
            if ctx["event_type"]:
                pieces.append(f"–¢–∏–ø: {ctx['event_type']}")
            if ctx["description"]:
                pieces.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {_truncate_context(ctx['description'])}")
            contexts.append(f"{idx}. " + " | ".join(pieces))

        prompt_titles = "\n".join(contexts) if contexts else " | ".join(titles)
        prompt = (
            "–Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π.\n\n"
            "–ó–∞–¥–∞—á–∞: –≤–µ—Ä–Ω—É—Ç—å JSON-–º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤ –≤–∏–¥–∞:\n\n"
            '{"emoji": "üë•" | "", "title_clean": "–ù–∞–∑–≤–∞–Ω–∏–µ"}\n\n'
            "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n"
            "- –û—á–∏—Å—Ç–∏—Ç—å –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫.\n"
            "- –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤–µ–¥—É—â–∏–π —ç–º–æ–¥–∑–∏ (–µ—Å–ª–∏ –±—ã–ª) –≤ –ø–æ–ª–µ emoji.\n"
            "- –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–≤—ã—á–∫–∏ –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏.\n"
            "- –ï—Å–ª–∏ –ø–æ —Ç–∏–ø—É —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—é –≤–∏–¥–Ω–æ, —á—Ç–æ –≤—Å—Ç—Ä–µ—á–∞ —Å–æ–≤–º–µ—â–µ–Ω–∞ —Å –æ—Ç–∫—Ä—ã—Ç–∏–µ–º –≤—ã—Å—Ç–∞–≤–∫–∏, –¥–æ–±–∞–≤—å –≤ –∫–æ–Ω–µ—Ü –∑–∞–≥–æ–ª–æ–≤–∫–∞ –ø–æ—è—Å–Ω–µ–Ω–∏–µ ¬´‚Äî —Ç–≤–æ—Ä—á–µ—Å–∫–∞—è –≤—Å—Ç—Ä–µ—á–∞ –∏ –æ—Ç–∫—Ä—ã—Ç–∏–µ –≤—ã—Å—Ç–∞–≤–∫–∏¬ª.\n"
            "- –ë–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤, —Ç–æ–ª—å–∫–æ JSON.\n\n"
            "–°–æ–±—ã—Ç–∏—è:\n"
            + prompt_titles
        )

        logging.info(
            "digest.titles.llm.request kind=%s n=%s prompt_len=%s",
            "meetups",
            len(titles),
            len(prompt),
        )
        start = time.monotonic()
        try:
            text = await ask_4o(prompt, max_tokens=300)
        except Exception:
            took_ms = int((time.monotonic() - start) * 1000)
            logging.info(
                "digest.titles.llm.response error text_len=0 took_ms=%s", took_ms
            )
            return [
                _normalize_title_fallback(t, event_kind="meetups", event=ev)
                for t, ev in zip(titles, events_list)
            ]

        took_ms = int((time.monotonic() - start) * 1000)
        text = text.strip()
        logging.info(
            "digest.titles.llm.response ok text_len=%s took_ms=%s",
            len(text),
            took_ms,
        )

        try:
            data = json.loads(text)
            result: List[dict[str, str]] = []
            for orig, item, event in zip(titles, data, events_list):
                emoji = item.get("emoji") or ""
                title_clean_raw = item.get("title_clean") or item.get("title") or orig
                title_clean = _apply_meetup_postprocessing(title_clean_raw, event)
                result.append({"emoji": emoji, "title_clean": title_clean})
                logging.info(
                    "digest.titles.llm.sample kind=%s before=%r after=%r emoji=%s",
                    "meetups",
                    orig,
                    title_clean,
                    emoji,
                )
            if len(result) == len(titles):
                return result
        except Exception:
            pass

        return [
            _normalize_title_fallback(t, event_kind="meetups", event=ev)
            for t, ev in zip(titles, events_list)
        ]

    from main import ask_4o  # local import to avoid a cycle
    import json

    prompt_titles = " | ".join(titles)
    kind = event_kind if event_kind in {"lecture", "masterclass"} else "lecture"
    if kind == "masterclass":
        event_word = "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å"
        removal_phrase = "¬´–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å¬ª, ¬´–ú–∞—Å—Ç–µ—Ä –∫–ª–∞—Å—Å¬ª"
        role_word = "–≤–µ–¥—É—â–µ–≥–æ"
        examples = [
            '–í—Ö–æ–¥: ¬´üé® –ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å –ú–∞—Ä–∏–∏ –ò–≤–∞–Ω–æ–≤–æ–π ¬´–ë–æ—Ç–∞–Ω–∏—á–µ—Å–∫–∞—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è¬ª¬ª ‚Üí {"emoji":"üé®","title_clean":"–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å –ú–∞—Ä–∏–∏ –ò–≤–∞–Ω–æ–≤–æ–π: –ë–æ—Ç–∞–Ω–∏—á–µ—Å–∫–∞—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è"}\n',
            '–í—Ö–æ–¥: ¬´–ú–∞—Å—Ç–µ—Ä –∫–ª–∞—Å—Å ‚Äú–ì–æ—Ç–æ–≤–∏–º —à—Ç—Ä—É–¥–µ–ª—å‚Äù¬ª ‚Üí {"emoji":"","title_clean":"–ì–æ—Ç–æ–≤–∏–º —à—Ç—Ä—É–¥–µ–ª—å"}\n',
            '–í—Ö–æ–¥: ¬´üßµ –ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å ¬´–í—ã—à–∏–≤–∫–∞ –≥–ª–∞–¥—å—é –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö¬ª¬ª ‚Üí {"emoji":"üßµ","title_clean":"–í—ã—à–∏–≤–∫–∞ –≥–ª–∞–¥—å—é –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö"}\n',
        ]
    else:
        event_word = "–õ–µ–∫—Ü–∏—è"
        removal_phrase = "¬´–õ–µ–∫—Ü–∏—è¬ª, ¬´–õ–µ–∫—Ç–æ—Ä–∏–π¬ª"
        role_word = "–ª–µ–∫—Ç–æ—Ä–∞"
        examples = [
            '–í—Ö–æ–¥: ¬´üìö –õ–µ–∫—Ü–∏—è –ê–ª—ë–Ω—ã –ú–∏—Ä–æ—à–Ω–∏—á–µ–Ω–∫–æ ¬´–ú–æ–¥–∞ –§—Ä–∞–Ω—Ü–∏–∏‚Ä¶¬ª¬ª ‚Üí {"emoji":"üìö","title_clean":"–õ–µ–∫—Ü–∏—è –ê–ª—ë–Ω—ã –ú–∏—Ä–æ—à–Ω–∏—á–µ–Ω–∫–æ: –ú–æ–¥–∞ –§—Ä–∞–Ω—Ü–∏–∏‚Ä¶"}\n',
            '–í—Ö–æ–¥: ¬´–õ–µ–∫—Ç–æ—Ä–∏–π –ò–ª—å–∏ –î–µ–º–µ–Ω—Ç—å–µ–≤–∞ ‚Äú–û—Ç –∫–∞–º–µ–Ω–Ω–æ–≥–æ –≤–µ–∫–∞‚Ä¶‚Äù¬ª ‚Üí {"emoji":"","title_clean":"–õ–µ–∫—Ü–∏—è –ò–ª—å–∏ –î–µ–º–µ–Ω—Ç—å–µ–≤–∞: –û—Ç –∫–∞–º–µ–Ω–Ω–æ–≥–æ –≤–µ–∫–∞‚Ä¶"}\n',
            '–í—Ö–æ–¥: ¬´–õ–µ–∫—Ü–∏—è ¬´–î—Ä–µ–≤–Ω–µ—Ä—É—Å—Å–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–æ. –ú–∞—Å—Ç–µ—Ä–∞ –∏ —ç–ø–æ—Ö–∏¬ª¬ª ‚Üí {"emoji":"","title_clean":"–î—Ä–µ–≤–Ω–µ—Ä—É—Å—Å–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–æ. –ú–∞—Å—Ç–µ—Ä–∞ –∏ —ç–ø–æ—Ö–∏"}\n',
        ]

    examples_str = "".join(examples)
    prompt = (
        "–Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π.\n\n"
        "–ó–∞–¥–∞—á–∞: –≤–µ—Ä–Ω—É—Ç—å JSON-–º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤ –≤–∏–¥–∞:\n\n"
        f'{{"emoji": "üìö" | "", "title_clean": "{event_word} –ò–º—è –§–∞–º–∏–ª–∏—è: –ù–∞–∑–≤–∞–Ω–∏–µ" | "–ù–∞–∑–≤–∞–Ω–∏–µ"}}\n\n'
        "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n\n"
        f"–£–¥–∞–ª—è—Ç—å —Å–ª–æ–≤–∞ {removal_phrase} –∏ —Ç.–ø. –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞.\n\n"
        f"–ï—Å–ª–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –Ω–∞–∑–≤–∞–Ω–∏–∏ –µ—Å—Ç—å –∏–º—è {role_word} (–≤ –ª—é–±–æ–π —Ñ–æ—Ä–º–µ), –ø—Ä–∏–≤–µ—Å—Ç–∏ –∏–º—è –∏ —Ñ–∞–º–∏–ª–∏—é –∫ —Ä–æ–¥–∏—Ç–µ–ª—å–Ω–æ–º—É –ø–∞–¥–µ–∂—É (–†.–ø.) –±–µ–∑ –æ—Ç—á–µ—Å—Ç–≤–∞ –∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫: '{event_word} –ò–º—è –§–∞–º–∏–ª–∏—è: –ù–∞–∑–≤–∞–Ω–∏–µ'.\n\n"
        f"–ï—Å–ª–∏ {role_word} –Ω–µ—Ç ‚Äî –ø—Ä–æ—Å—Ç–æ '–ù–∞–∑–≤–∞–Ω–∏–µ' –±–µ–∑ —Å–ª–æ–≤–∞ '{event_word}'.\n\n"
        "–í–µ–¥—É—â–∏–π —ç–º–æ–¥–∑–∏ (–µ—Å–ª–∏ –±—ã–ª) –≤–µ—Ä–Ω—É—Ç—å –≤ –ø–æ–ª–µ emoji (–Ω–µ –≤–Ω—É—Ç—Ä–∏ title_clean).\n\n"
        "–ë–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤/–ø–æ—è—Å–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ JSON.\n\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        + examples_str
        + "\n"
        "–ó–∞–≥–æ–ª–æ–≤–∫–∏: "
        + prompt_titles
    )
    logging.info(
        "digest.titles.llm.request kind=%s n=%s prompt_len=%s",
        kind,
        len(titles),
        len(prompt),
    )
    start = time.monotonic()
    try:
        text = await ask_4o(prompt, max_tokens=300)
    except Exception:
        took_ms = int((time.monotonic() - start) * 1000)
        logging.info(
            "digest.titles.llm.response error text_len=0 took_ms=%s", took_ms
        )
        return [
            _normalize_title_fallback(t, event_kind=kind, event=ev)
            for t, ev in zip(titles, events_list)
        ]

    took_ms = int((time.monotonic() - start) * 1000)
    text = text.strip()
    logging.info(
        "digest.titles.llm.response ok text_len=%s took_ms=%s", len(text), took_ms
    )

    try:
        data = json.loads(text)
        result: List[dict[str, str]] = []
        for orig, item, event in zip(titles, data, events_list):
            emoji = item.get("emoji") or ""
            title_clean = item.get("title_clean") or item.get("title") or orig
            result.append({"emoji": emoji, "title_clean": title_clean})
            logging.info(
                "digest.titles.llm.sample kind=%s before=%r after=%r emoji=%s",
                kind,
                orig,
                title_clean,
                emoji,
            )
        if len(result) == len(titles):
            return result
    except Exception:
        pass

    return [
        _normalize_title_fallback(t, event_kind=kind, event=ev)
        for t, ev in zip(titles, events_list)
    ]




_LEADING_EMOJI_RE = re.compile(
    r"^([\U0001F300-\U0010FFFF](?:\uFE0F|[\U0001F3FB-\U0001F3FF])?"
    r"(?:\u200D[\U0001F300-\U0010FFFF](?:\uFE0F|[\U0001F3FB-\U0001F3FF])?)*)"
)


def _split_leading_emoji(title: str) -> tuple[str, str]:
    match = _LEADING_EMOJI_RE.match(title)
    if not match:
        return "", title
    emoji = match.group(0)
    return emoji, title[len(emoji) :]


_NAME_PART_RE = re.compile(r"^[A-Z–ê-–Ø–Å][a-z–∞-—è—ë]+(?:-[A-Z–ê-–Ø–Å][a-z–∞-—è—ë]+)*$")


def _looks_like_full_name(candidate: str) -> bool:
    parts = candidate.split()
    if len(parts) != 2:
        return False
    return all(_NAME_PART_RE.match(part) for part in parts)


def _normalize_title_fallback(
    title: str, *, event_kind: str = "lecture", event: Any | None = None
) -> dict[str, str]:
    """Fallback normalization used when LLM is unavailable."""

    emoji, rest = _split_leading_emoji(title)

    if event_kind == "exhibition":
        return _normalize_exhibition_title(title)

    if event_kind == "meetups":
        cleaned = re.sub(r"\s+", " ", rest).strip() or rest.strip() or title.strip()
        cleaned = _apply_meetup_postprocessing(cleaned, event)
        return {"emoji": emoji, "title_clean": cleaned}

    kind = event_kind if event_kind in {"lecture", "masterclass"} else "lecture"
    if kind == "masterclass":
        removal_pattern = r"^(?:[^\w]*?)*(?:–ú–∞—Å—Ç–µ—Ä[\s-]*–∫–ª–∞—Å—Å)[\s:‚Äî-]*"
        prefix = "–ú–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å"
    else:
        removal_pattern = r"^(?:[^\w]*?)*(?:–õ–µ–∫—Ü–∏—è|–õ–µ–∫—Ç–æ—Ä–∏–π)[\s:‚Äî-]*"
        prefix = "–õ–µ–∫—Ü–∏—è"

    title = re.sub(removal_pattern, "", rest, flags=re.IGNORECASE)
    title = re.sub(r"^–æ—Ç\s+", "", title, flags=re.IGNORECASE)
    title = re.sub(r"\s+", " ", title).strip()

    m = re.match(
        r"^(?P<who>[\w–Å—ë–ê-–Ø–∞-—è-]+\s+[\w–Å—ë–ê-–Ø–∞-—è-]+)[\s‚Äî:-]+(?P<what>.+)$",
        title,
    )
    if m:
        who = m.group("who").strip()
        what = m.group("what").strip()
        if _looks_like_full_name(who):
            title = f"{prefix} {who}: {what}"

    return {"emoji": emoji, "title_clean": title}


def pick_display_link(event: Event) -> str | None:
    """Return a display link for ``event`` if available.

    Priority:
    1. ``source_post_url``
    2. ``telegraph_url``
    3. ``telegraph_path`` (normalized to ``https://telegra.ph``)

    Additionally logs the chosen source.
    """

    chosen = "none"
    url = None
    if event.source_post_url:
        url = event.source_post_url
        chosen = "source_post"
    elif event.telegraph_url:
        url = event.telegraph_url
        chosen = "telegraph"
    elif event.telegraph_path:
        url = f"https://telegra.ph/{event.telegraph_path.lstrip('/')}"
        chosen = "path"
    logging.info(
        "digest.link.pick event_id=%s chosen=%s url=%s",
        getattr(event, "id", None),
        chosen,
        url,
    )
    return url


def format_event_line_html(
    event: Event,
    link_url: str | None,
    *,
    emoji: str = "",
    title_override: str | None = None,
) -> str:
    """Format event information for digest list as HTML.

    Parameters
    ----------
    event:
        Source event.
    link_url:
        URL to wrap the title into. ``None`` disables the link.
    emoji:
        Optional emoji placed before the title. When present the ``|``
        separator is omitted as the emoji acts as a visual marker.
    title_override:
        Normalized title to use instead of ``event.title``.
    """

    dt = datetime.strptime(event.date, "%Y-%m-%d")
    date_part = dt.strftime("%d.%m")
    is_exhibition = (event.event_type or "").lower() == "–≤—ã—Å—Ç–∞–≤–∫–∞"
    if is_exhibition:
        end_raw = getattr(event, "end_date", None)
        if end_raw:
            try:
                end_dt = datetime.strptime(end_raw, "%Y-%m-%d")
            except ValueError:
                logging.warning(
                    "digest.end_date.format event_id=%s end_date_raw=%r",
                    getattr(event, "id", None),
                    end_raw,
                )
            else:
                date_part = f"–ø–æ {end_dt.strftime('%d.%m')}"
        else:
            logging.warning(
                "digest.end_date.missing event_id=%s event_type=%r",
                getattr(event, "id", None),
                event.event_type,
            )
        if not date_part.startswith("–ø–æ "):
            date_part = f"–ø–æ {dt.strftime('%d.%m')}"
        time_part = ""
    else:
        time_part = ""
        parsed = parse_start_time(event.time or "")
        if parsed is not None:
            hh, mm = parsed
            time_part = f" {hh:02d}:{mm:02d}"
        else:
            logging.warning(
                "digest.time.format event_id=%s time_raw=%r parsed=none",
                getattr(event, "id", None),
                event.time,
            )

    title = title_override or event.title
    if link_url:
        title_part = f'<a href="{link_url}">{title}</a>'
    else:
        title_part = title

    if emoji:
        return f"{date_part}{time_part} {emoji} {title_part}".strip()
    return f"{date_part}{time_part} | {title_part}"


def _truncate_html_title(line: str, limit: int) -> str:
    """Truncate title text inside HTML link in ``line`` to ``limit`` chars."""

    def repl(match: re.Match[str]) -> str:
        url = match.group("url")
        title = match.group("title")
        if len(title) > limit:
            title = title[: limit - 3] + "..."
        return f'<a href="{url}">{title}</a>'

    return re.sub(r'<a href="(?P<url>[^"]+)">(?P<title>[^<]+)</a>', repl, line)


def _strip_quotes_dashes(line: str) -> str:
    """Remove angle quotes and long dashes from title part of ``line``."""

    def repl(match: re.Match[str]) -> str:
        url = match.group("url")
        title = match.group("title").replace("¬´", "").replace("¬ª", "").replace("‚Äî", "-")
        return f'<a href="{url}">{title}</a>'

    return re.sub(r'<a href="(?P<url>[^"]+)">(?P<title>[^<]+)</a>', repl, line)


def visible_caption_len(html_text: str) -> int:
    """Return length of caption text visible to humans.

    The function removes HTML tags while keeping the inner text of
    anchors, strips raw ``http(s)://`` URLs and collapses repeating
    whitespace and newlines. The result mirrors the length counted by
    Telegram for media group captions.
    """

    # Replace anchors with their inner text
    s = re.sub(r"<a\s+[^>]*>(.*?)</a>", r"\1", html_text, flags=re.IGNORECASE | re.DOTALL)
    # Drop all remaining tags
    s = re.sub(r"<[^>]+>", "", s)
    # Decode HTML entities
    s = html.unescape(s)
    # Remove raw URLs that might remain in text
    s = re.sub(r"https?://\S+", "", s)
    # Normalize whitespace and newlines
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\n+", "\n", s)
    s = s.strip()
    return len(s)


def attach_caption_if_fits(
    media: List["types.InputMediaPhoto"], caption_html: str
) -> tuple[bool, int]:
    """Attach caption to first media item if visible length allows.

    Returns a tuple ``(attached, visible_len)`` where ``attached`` indicates
    whether the caption was placed on the first photo and ``visible_len`` is the
    human‚Äëvisible length of ``caption_html``.  The function mutates ``media`` in
    place when attaching the caption.
    """

    from aiogram import types

    visible_len = visible_caption_len(caption_html)
    if media and visible_len <= 1024:
        first = media[0]
        media[0] = types.InputMediaPhoto(
            media=first.media, caption=caption_html, parse_mode="HTML"
        )
        return True, visible_len
    return False, visible_len


async def compose_digest_caption(
    intro_text: str,
    lines_html: List[str],
    footer_html: str,
    excluded: Iterable[int] | None = None,
    *,
    digest_id: str | None = None,
) -> tuple[str, List[str]]:
    """Compose digest caption respecting Telegram visible length limits."""

    excluded_set = set(excluded or [])
    lines = [
        line for idx, line in enumerate(lines_html) if idx not in excluded_set
    ]

    def build_caption(current: List[str]) -> str:
        body = intro_text.strip()
        if current:
            body += "\n\n" + "\n".join(current)
        body += "\n\n" + footer_html
        return body

    caption = build_caption(lines)
    visible_len = visible_caption_len(caption)
    while lines and visible_len > 4096:
        lines.pop()
        caption = build_caption(lines)
        visible_len = visible_caption_len(caption)
    logging.info(
        "digest.caption.compose digest_id=%s visible_len=%s fit_1024=%s",
        digest_id,
        visible_len,
        int(visible_len <= 1024),
    )
    return caption, lines


async def assemble_compact_caption(
    intro: str, items_html: List[str], *, digest_id: str | None = None
) -> tuple[str, List[str]]:
    """Assemble caption trimmed to Telegram's 4096 char visible limit."""

    footer = '<a href="https://t.me/kenigevents">–ü–æ–ª—é–±–∏—Ç—å –ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥ | –ê–Ω–æ–Ω—Å—ã</a>'
    return await compose_digest_caption(
        intro, items_html, footer, excluded=None, digest_id=digest_id
    )


async def _build_digest_preview(
    digest_id: str,
    db: Database,
    now: datetime,
    *,
    kind: str,
    event_noun: str,
    event_kind: str,
    candidates_builder: Callable[
        [Database, datetime, str | None], Awaitable[Tuple[List[Event], int]]
    ],
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Generic helper for assembling digest previews."""

    start = time.monotonic()
    logging.info(
        "digest.collect.start digest_id=%s kind=%s window_days=14 now=%s limit=9",
        digest_id,
        kind,
        now.isoformat(),
    )
    events, horizon = await candidates_builder(db, now, digest_id)
    duration_ms = int((time.monotonic() - start) * 1000)
    cutoff_plus_2h = now + timedelta(hours=2)
    logging.info(
        "digest.collect.end digest_id=%s kind=%s window_days=%s now=%s cutoff_plus_2h=%s count_found=%s count_after_filters=%s limit=9 duration_ms=%s",
        digest_id,
        kind,
        horizon,
        now.isoformat(),
        cutoff_plus_2h.isoformat(),
        len(events),
        len(events),
        duration_ms,
    )

    if not events:
        return "", [], horizon, [], []

    titles = [e.title for e in events]
    normalized = await normalize_titles_via_4o(
        titles, event_kind=event_kind, events=events
    )

    if event_kind == "masterclass":
        masterclasses_payload: List[dict[str, str]] = []
        for ev, norm in zip(events, normalized):
            title_clean = norm.get("title_clean") or ev.title
            masterclasses_payload.append(
                {
                    "title": title_clean,
                    "description": (ev.description or "").strip(),
                }
            )
        intro = await compose_masterclasses_intro_via_4o(
            len(events), horizon, masterclasses_payload
        )
    elif event_kind == "exhibition":
        exhibitions_payload: List[dict[str, object]] = []
        for ev, norm in zip(events, normalized):
            title_clean = norm.get("title_clean") or ev.title
            exhibitions_payload.append(
                {
                    "title": title_clean,
                    "description": (ev.description or "").strip(),
                    "date_range": {
                        "start": ev.date,
                        "end": ev.end_date or ev.date,
                    },
                }
            )
        intro = await compose_exhibitions_intro_via_4o(
            len(events), horizon, exhibitions_payload
        )
    elif event_kind == "psychology":
        psychology_payload: List[dict[str, object]] = []
        for ev, norm in zip(events, normalized):
            title_clean = norm.get("title_clean") or ev.title
            psychology_payload.append(
                {
                    "title": title_clean,
                    "description": (ev.description or "").strip(),
                    "topics": normalize_topics(getattr(ev, "topics", [])),
                }
            )
        intro = await compose_psychology_intro_via_4o(
            len(events), horizon, psychology_payload
        )
    elif event_kind == "meetups":
        meetups_payload: List[dict[str, object]] = []
        tone_counter: Counter[str] = Counter()
        for ev, norm in zip(events, normalized):
            title_clean = norm.get("title_clean") or ev.title
            description = (ev.description or "").strip()
            meetups_payload.append(
                {
                    "title": title_clean,
                    "description": description,
                    "event_type": (ev.event_type or "").strip(),
                    "formats": _detect_meetup_formats(ev, norm),
                }
            )
            _update_meetups_tone(tone_counter, f"{title_clean} {description}")
        tone_hint = _select_meetups_tone_hint(tone_counter)
        intro = await compose_meetups_intro_via_4o(
            len(events), horizon, meetups_payload, tone_hint
        )
    else:
        intro = await compose_digest_intro_via_4o(
            len(events), horizon, titles, event_noun=event_noun
        )
    lines: List[str] = []
    norm_titles: List[str] = []
    for ev, norm in zip(events, normalized):
        link = pick_display_link(ev)
        title_clean = norm.get("title_clean")
        norm_titles.append(title_clean or ev.title)
        lines.append(
            format_event_line_html(
                ev,
                link,
                emoji=norm.get("emoji", ""),
                title_override=title_clean,
            )
        )
    return intro, lines, horizon, events, norm_titles


async def build_lectures_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for lectures."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="lectures",
        event_noun="–ª–µ–∫—Ü–∏–π",
        event_kind="lecture",
        candidates_builder=build_lectures_digest_candidates,
    )


async def build_masterclasses_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for master-classes."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="masterclasses",
        event_noun="–º–∞—Å—Ç–µ—Ä-–∫–ª–∞—Å—Å–æ–≤",
        event_kind="masterclass",
        candidates_builder=build_masterclasses_digest_candidates,
    )


async def build_exhibitions_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for exhibitions."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="exhibitions",
        event_noun="–≤—ã—Å—Ç–∞–≤–æ–∫",
        event_kind="exhibition",
        candidates_builder=build_exhibitions_digest_candidates,
    )


async def build_psychology_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for psychology events."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="psychology",
        event_noun="–ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π",
        event_kind="psychology",
        candidates_builder=build_psychology_digest_candidates,
    )


async def build_science_pop_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for science-pop events."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="science_pop",
        event_noun="–Ω–∞—É—á–Ω–æ-–ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π",
        event_kind="science_pop",
        candidates_builder=build_science_pop_digest_candidates,
    )


async def build_kraevedenie_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for Kaliningrad heritage events."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="kraevedenie",
        event_noun="–∫—Ä–∞–µ–≤–µ–¥—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π",
        event_kind="kraevedenie",
        candidates_builder=build_kraevedenie_digest_candidates,
    )


async def build_networking_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for networking events."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="networking",
        event_noun="–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥–æ–≤",
        event_kind="networking",
        candidates_builder=build_networking_digest_candidates,
    )


async def build_entertainment_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for entertainment events."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="entertainment",
        event_noun="—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–π",
        event_kind="entertainment",
        candidates_builder=build_entertainment_digest_candidates,
    )


async def build_markets_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for handmade markets."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="markets",
        event_noun="–º–∞—Ä–∫–µ—Ç–æ–≤",
        event_kind="markets",
        candidates_builder=build_markets_digest_candidates,
    )


async def build_theatre_classic_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for classic theatre performances."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="theatre_classic",
        event_noun="–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö —Å–ø–µ–∫—Ç–∞–∫–ª–µ–π",
        event_kind="theatre_classic",
        candidates_builder=build_theatre_classic_digest_candidates,
    )


async def build_theatre_modern_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for modern theatre performances."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="theatre_modern",
        event_noun="—Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–ø–µ–∫—Ç–∞–∫–ª–µ–π",
        event_kind="theatre_modern",
        candidates_builder=build_theatre_modern_digest_candidates,
    )


async def build_meetups_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for meetups and clubs."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="meetups",
        event_noun="–≤—Å—Ç—Ä–µ—á –∏ –∫–ª—É–±–æ–≤",
        event_kind="meetups",
        candidates_builder=build_meetups_digest_candidates,
    )


async def build_movies_digest_preview(
    digest_id: str, db: Database, now: datetime
) -> tuple[str, List[str], int, List[Event], List[str]]:
    """Build digest preview text for movie screenings."""

    return await _build_digest_preview(
        digest_id,
        db,
        now,
        kind="movies",
        event_noun="–∫–∏–Ω–æ–ø–æ–∫–∞–∑–æ–≤",
        event_kind="movies",
        candidates_builder=build_movies_digest_candidates,
    )


