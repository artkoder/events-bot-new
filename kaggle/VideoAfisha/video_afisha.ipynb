{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d102c7",
   "metadata": {},
   "source": [
    "# Video Afisha Events Bot\n",
    "–ù–æ—É—Ç–±—É–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –¥–ª—è –±–æ—Ç–∞ —Å–æ–±—ã—Ç–∏–π –ö–∞–ª–∏–Ω–∏–Ω–≥—Ä–∞–¥–∞.\n",
    "\n",
    "**–í–µ—Ä—Å–∏—è –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è events-bot-new**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_VERSION = 'v24.15-fix-mask'\n",
    "print(f'üöÄ Engine {NOTEBOOK_VERSION}')\n",
    "\n",
    "# ==========================================\n",
    "# 1. –ò–ú–ü–û–†–¢–´ –ò –ù–ê–°–¢–†–û–ô–ö–ò\n",
    "# ==========================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. –£–°–¢–ê–ù–û–í–ö–ê –ë–ò–ë–õ–ò–û–¢–ï–ö\n",
    "print(\"‚è≥ Installing libraries...\", flush=True)\n",
    "!pip install moviepy==1.0.3 numpy requests telethon > /dev/null\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import asyncio\n",
    "import requests\n",
    "import glob\n",
    "\n",
    "# --- –í–ê–ñ–ù–´–ï –ò–ú–ü–û–†–¢–´ ---\n",
    "import numpy as np             \n",
    "from PIL import Image, ImageFont, ImageDraw, ImageFilter\n",
    "\n",
    "# Telethon & Secrets\n",
    "from telethon import TelegramClient\n",
    "from telethon.sessions import StringSession\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# MoviePy\n",
    "os.environ[\"SDL_AUDIODRIVER\"] = \"dummy\"\n",
    "from moviepy.editor import *\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ª–æ–≥–≥–∏–Ω–≥–∞\n",
    "def log(msg):\n",
    "    print(msg, flush=True)\n",
    "\n",
    "log(\"üöÄ Engine v24.15-fix-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•\n",
    "# ==========================================\n",
    "# --- –ê–í–¢–û-–ü–û–ò–°–ö –ü–ê–ü–ö–ò –î–ê–¢–ê–°–ï–¢–ê (FIX FOR BOT) ---\n",
    "KAGGLE_INPUT_ROOT = \"/kaggle/input\"\n",
    "# –ò—â–µ–º –ø–∞–ø–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å video-afisha-session-\n",
    "session_dirs = sorted(glob.glob(os.path.join(KAGGLE_INPUT_ROOT, \"video-afisha-session-*\")), reverse=True)\n",
    "\n",
    "if session_dirs:\n",
    "    # –ë–µ—Ä–µ–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –ø–∞–ø–∫—É —Å–µ—Å—Å–∏–∏\n",
    "    SOURCE_FOLDER = session_dirs[0]\n",
    "    log(f\"‚úÖ DETECTED BOT SESSION: {SOURCE_FOLDER}\")\n",
    "elif os.path.exists(os.path.join(KAGGLE_INPUT_ROOT, \"afisha-dataset-2\")):\n",
    "    # –§–æ–ª–±—ç–∫ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤\n",
    "    SOURCE_FOLDER = os.path.join(KAGGLE_INPUT_ROOT, \"afisha-dataset-2\")\n",
    "    log(f\"‚ö†Ô∏è Using legacy dataset: {SOURCE_FOLDER}\")\n",
    "else:\n",
    "    # –ï—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ –Ω–µ—Ç, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –ø–æ–ø–∞–≤—à—É—é—Å—è –ø–∞–ø–∫—É –≤ input\n",
    "    all_dirs = [d for d in glob.glob(os.path.join(KAGGLE_INPUT_ROOT, \"*\")) if os.path.isdir(d)]\n",
    "    if all_dirs:\n",
    "        SOURCE_FOLDER = all_dirs[0]\n",
    "        log(f\"‚ö†Ô∏è Using generic first folder: {SOURCE_FOLDER}\")\n",
    "    else:\n",
    "        SOURCE_FOLDER = \"/kaggle/input/afisha-dataset-2\" # –ß—Ç–æ–±—ã –Ω–µ —É–ø–∞–ª–æ —Å—Ä–∞–∑—É, –Ω–æ —É–ø–∞–¥–µ—Ç –ø–æ–∑–∂–µ\n",
    "        log(\"‚ùå CRITICAL: NO INPUT DATASET FOUND!\")\n",
    "\n",
    "WORKING_DIR = \"/kaggle/working\"\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–¥–µ–æ\n",
    "W, H = 1080, 1920\n",
    "FPS = 30\n",
    "AUDIO_START_SEC = 294   \n",
    "\n",
    "SPLIT_RATIO = 0.6 \n",
    "SPLIT_Y_COORD = int(H * SPLIT_RATIO) \n",
    "\n",
    "# –®—Ä–∏—Ñ—Ç—ã (–∏—â–µ–º –≤–Ω—É—Ç—Ä–∏ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –ø–∞–ø–∫–∏)\n",
    "FONT_PATH = os.path.join(SOURCE_FOLDER, \"BebasNeue-Bold.ttf\")\n",
    "if not os.path.exists(FONT_PATH):\n",
    "    # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫, –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è\n",
    "    found = glob.glob(os.path.join(KAGGLE_INPUT_ROOT, \"**/*.ttf\"), recursive=True)\n",
    "    FONT_PATH = found[0] if found else None\n",
    "    if FONT_PATH: log(f\"Generic font found: {FONT_PATH}\")\n",
    "\n",
    "# –¶–≤–µ—Ç–∞\n",
    "COLOR_TITLE = 'white'\n",
    "COLOR_ACCENT = '#f1c40f' \n",
    "COLOR_DETAILS = '#bdc3c7'\n",
    "BG_STRIP_COLOR = (80, 20, 140, 255) \n",
    "\n",
    "# –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥\n",
    "DEFAULT_RAW_DATA = {\n",
    "  \"intro\": {\"count\": 2, \"text\": \"–¢–ï–°–¢ –ó–ê–ì–†–£–ó–ö–ò\"},\n",
    "  \"scenes\": [\n",
    "    {\n",
    "      \"about\": \"–¢–µ—Å—Ç: –§–∞–π–ª –∏–∑ Telegram\",\n",
    "      \"date\": \"25 –¥–µ–∫–∞–±—Ä—è\", \"location\": \"–ö—ç—à Telegram\",\n",
    "      \"images\": [\"https://files.catbox.moe/vg30ot.jpg\"]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- –§–£–ù–ö–¶–ò–ò –ó–ê–ì–†–£–ó–ö–ò ---\n",
    "\n",
    "async def download_via_telegram(filenames_map):\n",
    "    \"\"\"–ö–∞—á–∞–µ—Ç —Ñ–∞–π–ª—ã –∏–∑ –ò–∑–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–ª–∏ –ö–∞–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ Telethon\"\"\"\n",
    "    if not filenames_map: return\n",
    "\n",
    "    log(f\"\\n--- üîµ Telegram: –ò—â–µ–º —Ñ–∞–π–ª—ã ({len(filenames_map)} —à—Ç) ---\")\n",
    "    \n",
    "    # 1. –ß–∏—Ç–∞–µ–º —Å–µ–∫—Ä–µ—Ç—ã\n",
    "    try:\n",
    "        secrets = UserSecretsClient()\n",
    "        api_id = int(secrets.get_secret(\"TELEGRAM_API_ID\"))\n",
    "        api_hash = secrets.get_secret(\"TELEGRAM_API_HASH\")\n",
    "        session_str = secrets.get_secret(\"TELEGRAM_SESSION\")\n",
    "        \n",
    "        channel_id = None\n",
    "        try:\n",
    "            cid = secrets.get_secret(\"SOURCE_CHANNEL_ID\")\n",
    "            if cid: channel_id = int(cid)\n",
    "        except: pass\n",
    "    except Exception as e:\n",
    "        log(f\"[SKIP] –ù–µ—Ç —Å–µ–∫—Ä–µ—Ç–æ–≤ –∏–ª–∏ –æ—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è\n",
    "    try:\n",
    "        client = TelegramClient(StringSession(session_str), api_id, api_hash)\n",
    "        await client.connect()\n",
    "        if not await client.is_user_authorized():\n",
    "            log(\"[ERROR] ‚ùå –°–µ—Å—Å–∏—è –Ω–µ–≤–∞–ª–∏–¥–Ω–∞! (–°–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–π–¥–µ—Ç –∫ HTTP)\")\n",
    "            await client.disconnect()\n",
    "            return\n",
    "        \n",
    "        target = channel_id if channel_id else \"me\"\n",
    "        target_name = \"CHANNEL\" if channel_id else \"SAVED MESSAGES\"\n",
    "        log(f\"   > –ü–æ–¥–∫–ª—é—á–µ–Ω–æ. –ò—â–µ–º –≤: {target_name}\")\n",
    "\n",
    "        for fname, local_path in filenames_map.items():\n",
    "            if os.path.exists(local_path): continue\n",
    "            \n",
    "            log(f\"   > –ü–æ–∏—Å–∫: {fname} ...\")\n",
    "            found_msg = None\n",
    "            try:\n",
    "                async for message in client.iter_messages(target, search=fname, limit=100):\n",
    "                    if message.media:\n",
    "                        found_msg = message\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                log(f\"     [ERR] {e}\")\n",
    "\n",
    "            if found_msg:\n",
    "                log(f\"     [FOUND] –°–∫–∞—á–∏–≤–∞–µ–º...\")\n",
    "                await found_msg.download_media(file=local_path)\n",
    "                log(\"     [DONE]\")\n",
    "            else:\n",
    "                log(\"     [NOT FOUND]\")\n",
    "        \n",
    "        await client.disconnect()\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f\"[TELEGRAM ERROR] {e}\")\n",
    "\n",
    "def download_via_http(url, local_path):\n",
    "    \"\"\"HTTP —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å User-Agent\"\"\"\n",
    "    if os.path.exists(local_path): return True\n",
    "    log(f\"   > HTTP Fallback: {url} ...\")\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36'}\n",
    "        r = requests.get(url, headers=headers, timeout=20)\n",
    "        if r.status_code == 200:\n",
    "            with open(local_path, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            log(\"     [OK]\")\n",
    "            return True\n",
    "        else:\n",
    "            log(f\"     [FAIL] Status {r.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        log(f\"     [ERR] {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_loader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ORCHESTRATOR ---\n",
    "\n",
    "async def main_loader():\n",
    "    # 1. –ü–æ–∏—Å–∫ payload.json\n",
    "    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π SOURCE_FOLDER\n",
    "    payload_path = os.path.join(SOURCE_FOLDER, \"payload.json\")\n",
    "    \n",
    "    if not os.path.exists(payload_path):\n",
    "         # –ï—Å–ª–∏ –Ω–µ—Ç, –∏—â–µ–º –≥–ª–æ–±–∞–ª—å–Ω–æ –≤–æ –≤—Å–µ–º input\n",
    "         candidates = glob.glob(os.path.join(KAGGLE_INPUT_ROOT, \"**/payload.json\"), recursive=True)\n",
    "         if candidates: payload_path = candidates[0]\n",
    "\n",
    "    if payload_path and os.path.exists(payload_path):\n",
    "        log(f\"FOUND PAYLOAD: {payload_path}\")\n",
    "        with open(payload_path, 'r', encoding='utf-8') as f:\n",
    "            raw = json.load(f)\n",
    "    else:\n",
    "        log(\"Using Internal Default Data\")\n",
    "        raw = DEFAULT_RAW_DATA\n",
    "\n",
    "    tasks_telegram = {} \n",
    "    url_map = {}        \n",
    "    \n",
    "    scenes = raw.get(\"scenes\", [])\n",
    "    for idx, scene in enumerate(scenes):\n",
    "        imgs = scene.get(\"images\", [])\n",
    "        if imgs and isinstance(imgs, list):\n",
    "            url = imgs[0]\n",
    "            if url.startswith(\"http\"):\n",
    "                fname = url.split(\"/\")[-1] \n",
    "                local_name = f\"scene_{idx}_{fname}\"\n",
    "                local_path = os.path.join(WORKING_DIR, local_name)\n",
    "                \n",
    "                tasks_telegram[fname] = local_path\n",
    "                url_map[url] = local_path\n",
    "\n",
    "    if tasks_telegram:\n",
    "        await download_via_telegram(tasks_telegram)\n",
    "    \n",
    "    log(\"\\n--- üü† –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è (HTTP) ---\")\n",
    "    final_assets = {}\n",
    "    for url, path in url_map.items():\n",
    "        if os.path.exists(path):\n",
    "            final_assets[url] = os.path.abspath(path)\n",
    "        else:\n",
    "            if download_via_http(url, path):\n",
    "                final_assets[url] = os.path.abspath(path)\n",
    "\n",
    "    processed = {\"intro\": {}, \"scenes\": []}\n",
    "    \n",
    "    ri = raw.get(\"intro\", {})\n",
    "    cnt = ri.get(\"count\")\n",
    "    processed[\"intro\"][\"count\"] = str(cnt) if cnt not in [None, 0, \"\"] else \"\"\n",
    "    processed[\"intro\"][\"text\"] = ri.get(\"text\", \"\")\n",
    "    processed[\"intro\"][\"cities\"] = ri.get(\"cities\", [])\n",
    "    processed[\"intro\"][\"date\"] = ri.get(\"date\", \"\")\n",
    "    processed[\"intro\"][\"pattern\"] = ri.get(\"pattern\", \"STICKER\")\n",
    "    \n",
    "    for scene in scenes:\n",
    "        new_s = {\n",
    "            \"title\": scene.get(\"about\", scene.get(\"title\", \"\")),\n",
    "            \"date\": scene.get(\"date\", \"\"),\n",
    "            \"location\": scene.get(\"location\", \"\"),\n",
    "            \"images\": []\n",
    "        }\n",
    "        if scene.get(\"images\"):\n",
    "            u = scene[\"images\"][0]\n",
    "            if u in final_assets:\n",
    "                new_s[\"images\"].append(final_assets[u])\n",
    "            elif not u.startswith(\"http\"):\n",
    "                new_s[\"images\"].append(u) \n",
    "        processed[\"scenes\"].append(new_s)\n",
    "        \n",
    "    return processed\n",
    "\n",
    "# –ó–ê–ü–£–°–ö\n",
    "CURRENT_SCENARIO = await main_loader()\n",
    "SCENES_DATA = CURRENT_SCENARIO.get(\"scenes\", [])\n",
    "INTRO_DATA = CURRENT_SCENARIO.get(\"intro\", {\"count\": \"\", \"text\": \"\"})\n",
    "\n",
    "log(\"\\n‚úÖ Data Ready. Starting Render Engine...\")\n",
    "random.seed(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "math_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê\n",
    "# ==========================================\n",
    "def ease_out_cubic(t): \n",
    "    return 1 - (1 - t)**3\n",
    "\n",
    "def ease_in_cubic(t): \n",
    "    return t * t * t\n",
    "\n",
    "def ease_in_expo_aggressive(t):\n",
    "    return 0 if t == 0 else pow(2, 12 * t - 12)\n",
    "\n",
    "def ease_out_quint(t):\n",
    "    return 1 - pow(1 - t, 5)\n",
    "\n",
    "def ease_in_out_quint(t):\n",
    "    if t < 0.5:\n",
    "        return 16 * t * t * t * t * t\n",
    "    else:\n",
    "        return 1 - pow(-2 * t + 2, 5) / 2\n",
    "        \n",
    "def ease_out_expo(t):\n",
    "    if t == 1: return 1\n",
    "    return 1 - pow(2, -10 * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text_engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. –¢–ï–ö–°–¢–û–í–´–ô –î–í–ò–ñ–û–ö\n",
    "# ==========================================\n",
    "def get_font_object(font_path, fontsize):\n",
    "    try:\n",
    "        return ImageFont.truetype(font_path, fontsize) if font_path else ImageFont.load_default()\n",
    "    except:\n",
    "        return ImageFont.load_default()\n",
    "\n",
    "\n",
    "\n",
    "def rgba_image_to_clip(img):\n",
    "    rgba = np.array(img.convert('RGBA'))\n",
    "    rgb = rgba[:, :, :3]\n",
    "    clip = ImageClip(rgb)\n",
    "    if rgba.shape[2] == 4:\n",
    "        alpha = rgba[:, :, 3].astype('float32') / 255.0\n",
    "        mask = ImageClip(alpha, ismask=True)\n",
    "        # MoviePy blit expects 2D mask frames; keep the mask 2D.\n",
    "        clip = clip.set_mask(mask)\n",
    "    return clip\n",
    "\n",
    "def create_word_clip_fixed_height(word, font, color, fixed_height, baseline_offset):\n",
    "    w_text = font.getlength(word)\n",
    "    pad_x = 10\n",
    "    w_canvas = int(w_text + pad_x * 2)\n",
    "    img = Image.new('RGBA', (w_canvas, fixed_height), (0, 0, 0, 0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    rect_top = 5\n",
    "    rect_bottom = fixed_height - 5\n",
    "    draw.rectangle([0, rect_top, w_canvas, rect_bottom], fill=(10, 10, 10, 240))\n",
    "    draw.text((pad_x, baseline_offset), word, font=font, fill=color)\n",
    "    return rgba_image_to_clip(img)\n",
    "\n",
    "def generate_kinetic_text(text, font_path, fontsize, color, start_time, duration, start_y):\n",
    "    font = get_font_object(font_path, fontsize)\n",
    "    try:\n",
    "        left, top, right, bottom = font.getbbox(\"Hg–ôj\")\n",
    "        ascent, descent = -top, bottom\n",
    "        line_height = ascent + descent + 5 \n",
    "        baseline_y = ascent + 2\n",
    "        clip_height = int(line_height + 10)\n",
    "    except:\n",
    "        clip_height = int(fontsize * 1.2)\n",
    "        baseline_y = int(fontsize * 0.2)\n",
    "    \n",
    "    raw_lines = text.split('\\n') if text else ['']\n",
    "    lines = []\n",
    "    space_w = font.getlength(' ')\n",
    "    max_w = W - 100\n",
    "    \n",
    "    for raw_line in raw_lines:\n",
    "        if not raw_line.strip():\n",
    "            lines.append([])\n",
    "            continue\n",
    "        words = [w for w in raw_line.split(' ') if w]\n",
    "        current_line = []\n",
    "        current_w = 0\n",
    "        for word in words:\n",
    "            word_w = font.getlength(word)\n",
    "            if current_line and current_w + word_w > max_w:\n",
    "                lines.append(current_line)\n",
    "                current_line = [word]\n",
    "                current_w = word_w + space_w\n",
    "            else:\n",
    "                current_line.append(word)\n",
    "                current_w += word_w + space_w\n",
    "        if current_line:\n",
    "            lines.append(current_line)\n",
    "\n",
    "    word_clips = []\n",
    "    current_y_pos = start_y\n",
    "    word_global_index = 0\n",
    "    \n",
    "    fly_in_dur = 0.7 \n",
    "    fly_in_dist = 200\n",
    "    fall_dur = 0.4\n",
    "    \n",
    "    for line in lines:\n",
    "        current_x = 50 \n",
    "        for word in line:\n",
    "            clip = create_word_clip_fixed_height(word, font, color, clip_height, baseline_y)\n",
    "            \n",
    "            delay = word_global_index * 0.05 \n",
    "            word_start = start_time + delay\n",
    "            \n",
    "            life_duration = duration - delay\n",
    "            if life_duration < (fall_dur + 0.1): life_duration = fall_dur + 0.1\n",
    "            \n",
    "            final_x = current_x\n",
    "            final_y = current_y_pos\n",
    "            \n",
    "            def pos_func(t, fx=final_x, fy=final_y, dur=life_duration):\n",
    "                if t < fly_in_dur:\n",
    "                    prog = t / fly_in_dur\n",
    "                    eased = ease_out_cubic(prog)\n",
    "                    curr_y = (fy + fly_in_dist) - (fly_in_dist * eased)\n",
    "                    return (fx, int(curr_y))\n",
    "                elif t > (dur - fall_dur):\n",
    "                    fall_t = t - (dur - fall_dur)\n",
    "                    prog = min(fall_t / fall_dur, 1.0)\n",
    "                    eased = ease_in_cubic(prog)\n",
    "                    curr_y = fy + (250 * eased)\n",
    "                    return (fx, int(curr_y))\n",
    "                else:\n",
    "                    return (fx, int(fy))\n",
    "\n",
    "            clip = (clip\n",
    "                    .set_start(word_start)\n",
    "                    .set_duration(life_duration)\n",
    "                    .set_position(pos_func)\n",
    "                    .crossfadein(0.2)\n",
    "                    .crossfadeout(fall_dur)) \n",
    "            \n",
    "            word_clips.append(clip)\n",
    "            real_w = clip.w \n",
    "            current_x += real_w + 5 \n",
    "            word_global_index += 1\n",
    "            \n",
    "        current_y_pos += clip_height + 2 \n",
    "        \n",
    "    return word_clips, current_y_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d_bento_engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. –î–í–ò–ñ–û–ö 3D –¢–ï–ö–°–¢–ê –ò –ë–ï–ù–¢–û\n",
    "# ==========================================\n",
    "\n",
    "def aspect_fill_crop(img, target_w, target_h):\n",
    "    src_w, src_h = img.size\n",
    "    src_ratio = src_w / src_h\n",
    "    dst_ratio = target_w / target_h\n",
    "    if src_ratio > dst_ratio:\n",
    "        resize_h = target_h\n",
    "        resize_w = int(target_h * src_ratio)\n",
    "    else:\n",
    "        resize_w = target_w\n",
    "        resize_h = int(target_w / src_ratio)\n",
    "    img_resized = img.resize((resize_w, resize_h), Image.LANCZOS)\n",
    "    left = (resize_w - target_w) // 2\n",
    "    top = (resize_h - target_h) // 2\n",
    "    return img_resized.crop((left, top, left + target_w, top + target_h))\n",
    "\n",
    "def make_3d_transform(start_x, start_y, start_scale, max_scale, t_start=0, speed_mult=1.0):\n",
    "    screen_cx = W / 2\n",
    "    screen_cy = H / 2\n",
    "    vec_x = start_x - screen_cx\n",
    "    vec_y = start_y - screen_cy\n",
    "    \n",
    "    def transform(t):\n",
    "        if t < t_start: return 1.0, (int(start_x), int(start_y))\n",
    "        prog = (t - t_start) * speed_mult\n",
    "        if prog > 1.5: prog = 1.5\n",
    "        factor = ease_in_expo_aggressive(prog/1.5)\n",
    "        curr_scale = 1.0 + (max_scale - 1.0) * factor\n",
    "        curr_x = screen_cx + vec_x * curr_scale\n",
    "        curr_y = screen_cy + vec_y * curr_scale\n",
    "        return curr_scale, (int(curr_x), int(curr_y))\n",
    "    return transform\n",
    "\n",
    "def create_single_word_clip(word, font_path, font_size, bg_color, text_color, target_height=None):\n",
    "    font = get_font_object(font_path, font_size)\n",
    "    \n",
    "    pad_x = 25\n",
    "    \n",
    "    if target_height:\n",
    "        # –†–µ–∂–∏–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã—Å–æ—Ç—ã (–ê—É—Ç—Ä–æ)\n",
    "        h = target_height\n",
    "        canvas_h = h\n",
    "        w_text = font.getlength(word)\n",
    "        bbox = font.getbbox(word)\n",
    "        h_text_real = bbox[3] - bbox[1]\n",
    "        pad_top = (canvas_h - h_text_real) // 2 - bbox[1] \n",
    "        y_pos = pad_top + 10\n",
    "        canvas_w = int(w_text + pad_x*2)\n",
    "    else:\n",
    "        # –†–µ–∂–∏–º –∞–≤—Ç–æ-–≤—ã—Å–æ—Ç—ã (–ò–Ω—Ç—Ä–æ) - UPD v24.0\n",
    "        \n",
    "        # 1. –≠—Ç–∞–ª–æ–Ω\n",
    "        bbox_sample = font.getbbox(\"Hg\") \n",
    "        sample_h = bbox_sample[3] - bbox_sample[1]\n",
    "        \n",
    "        # 2. –ï—â–µ –±–æ–ª–µ–µ —Å–∂–∞—Ç—ã–π –ø–∞–¥–¥–∏–Ω–≥ (1.25)\n",
    "        fixed_h = int(sample_h * 1.25) \n",
    "        canvas_h = fixed_h\n",
    "        \n",
    "        w_text = font.getlength(word)\n",
    "        canvas_w = int(w_text + pad_x*2)\n",
    "        \n",
    "        # 3. –ë–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è –ø–æ —ç—Ç–∞–ª–æ–Ω—É\n",
    "        y_pos = (fixed_h - sample_h) // 2 - bbox_sample[1]\n",
    "\n",
    "    img = Image.new('RGBA', (canvas_w, canvas_h), (0,0,0,0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    draw.rectangle([0, 0, canvas_w, canvas_h], fill=bg_color)\n",
    "    draw.text((pad_x, y_pos), word, font=font, fill=text_color)\n",
    "    \n",
    "    return rgba_image_to_clip(img), canvas_w, canvas_h\n",
    "\n",
    "def parse_intro_text_to_structure(text):\n",
    "    words = text.split()\n",
    "    if not words:\n",
    "        return [[(\"EVENTS\", 30.0)]]\n",
    "\n",
    "    lines_struct = []\n",
    "    current_chunk = []\n",
    "    \n",
    "    for i, w in enumerate(words):\n",
    "        is_long = len(w) > 4\n",
    "        \n",
    "        if is_long:\n",
    "            if current_chunk:\n",
    "                line_data = []\n",
    "                for cw in current_chunk:\n",
    "                    z = 25.0 if cw.isdigit() else 20.0\n",
    "                    line_data.append((cw, z))\n",
    "                lines_struct.append(line_data)\n",
    "                current_chunk = []\n",
    "            lines_struct.append([(w, 35.0)]) \n",
    "        else:\n",
    "            current_chunk.append(w)\n",
    "            if len(current_chunk) >= 2:\n",
    "                line_data = []\n",
    "                for cw in current_chunk:\n",
    "                    line_data.append((cw, 25.0))\n",
    "                lines_struct.append(line_data)\n",
    "                current_chunk = []\n",
    "\n",
    "    if current_chunk:\n",
    "        line_data = []\n",
    "        for cw in current_chunk:\n",
    "            line_data.append((cw, 25.0))\n",
    "        lines_struct.append(line_data)\n",
    "                \n",
    "    return lines_struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overlay_cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlay_cover(bento_images, intro_data):\n",
    "    DURATION = 2.5\n",
    "    \n",
    "    # DEBUG: Print intro_data to see what we receive\n",
    "    print(f\"[DEBUG] intro_data keys: {intro_data.keys()}\")\n",
    "    print(f\"[DEBUG] cities: {intro_data.get('cities', 'NOT FOUND')}\")\n",
    "    \n",
    "    # --- 1. BENTO GRID (unchanged) ---\n",
    "    layout = [\n",
    "        (0, 0, 1, 1), (1, 0, 1, 1), (2, 0, 1, 1),\n",
    "        (0, 1, 2, 2),               (2, 1, 1, 1), (2, 2, 1, 1),\n",
    "        (0, 3, 1, 1), (1, 3, 2, 2), (0, 4, 1, 1)\n",
    "    ]\n",
    "    needed = len(layout)\n",
    "    \n",
    "    if not bento_images:\n",
    "        pool = [\"placeholder\"] * needed\n",
    "    else:\n",
    "        pool = bento_images * (needed // len(bento_images) + 2)\n",
    "        random.shuffle(pool)\n",
    "    \n",
    "    COL_COUNT, PAD = 3, 15\n",
    "    GRID_W = 1200\n",
    "    UNIT = (GRID_W - (COL_COUNT + 1) * PAD) // COL_COUNT\n",
    "    START_X, START_Y = (W - GRID_W)//2, (H - (UNIT*5 + PAD*6))//2\n",
    "    \n",
    "    grid_clips = []\n",
    "    \n",
    "    def make_bento_logic(px, py, bw, bh, delay, speed):\n",
    "        cx, cy = W/2, H/2\n",
    "        def trans(t):\n",
    "            if t < delay: return 1.0, (px, py)\n",
    "            dt = (t - delay) * speed\n",
    "            prog = min(dt / 2.0, 1.0) \n",
    "            scale = 1.0 - ease_in_cubic(prog)\n",
    "            if scale < 0.01: scale = 0.01 \n",
    "            curr_cx = (px+bw/2) + (cx - (px+bw/2)) * ease_in_cubic(prog)\n",
    "            curr_cy = (py+bh/2) + (cy - (py+bh/2)) * ease_in_cubic(prog)\n",
    "            return scale, (int(curr_cx - bw*scale/2), int(curr_cy - bh*scale/2))\n",
    "        return trans\n",
    "\n",
    "    for i, (col, row, ws, hs) in enumerate(layout):\n",
    "        bw, bh = ws*UNIT + (ws-1)*PAD, hs*UNIT + (hs-1)*PAD\n",
    "        px, py = START_X + PAD + col*(UNIT+PAD), START_Y + PAD + row*(UNIT+PAD)\n",
    "        \n",
    "        if pool[i] != \"placeholder\":\n",
    "            path = os.path.join(SOURCE_FOLDER, pool[i])\n",
    "            if os.path.exists(path):\n",
    "                img = Image.open(path)\n",
    "                img = aspect_fill_crop(img, bw, bh).filter(ImageFilter.GaussianBlur(3))\n",
    "                \n",
    "                clip = rgba_image_to_clip(img).set_duration(DURATION).set_start(0)\n",
    "                if clip.mask is None:\n",
    "                    clip = clip.add_mask()\n",
    "                \n",
    "                delay = random.uniform(0.0, 0.6) \n",
    "                speed = random.uniform(1.2, 2.5) \n",
    "                \n",
    "                trans_func = make_bento_logic(px, py, bw, bh, delay, speed)\n",
    "                \n",
    "                moving = (clip.resize(lambda t, f=trans_func: f(t)[0])\n",
    "                              .set_position(lambda t, f=trans_func: f(t)[1])\n",
    "                              .crossfadeout(1.0)) \n",
    "                \n",
    "                grid_clips.append(moving)\n",
    "\n",
    "    # --- 2. STICKER PATTERN INTRO (v4 - Fixed cities) ---\n",
    "    intro_text = str(intro_data.get(\"text\", \"–°–û–ë–´–¢–ò–Ø\")).upper()\n",
    "    count_str = str(intro_data.get(\"count\", \"\"))\n",
    "    \n",
    "    # Handle cities - can be list or None\n",
    "    cities_raw = intro_data.get(\"cities\", None)\n",
    "    if isinstance(cities_raw, list):\n",
    "        cities_list = cities_raw\n",
    "    elif isinstance(cities_raw, str) and cities_raw:\n",
    "        cities_list = [c.strip() for c in cities_raw.split(',') if c.strip()]\n",
    "    else:\n",
    "        cities_list = []\n",
    "    \n",
    "    print(f\"[DEBUG] Parsed cities_list: {cities_list}\")\n",
    "    \n",
    "    # --- Parse intro text to lines ---\n",
    "    PREPOSITIONS = {'–ù–ê', '–í', '–î–û', '–î–õ–Ø', '–ò–ó', '–ü–û', '–°', '–ö', '–û', '–£', '–û–¢', '–ó–ê'}\n",
    "    \n",
    "    def group_words_with_prepositions(words):\n",
    "        result = []\n",
    "        i = 0\n",
    "        while i < len(words):\n",
    "            word = words[i]\n",
    "            if word in PREPOSITIONS and i + 1 < len(words):\n",
    "                result.append(word + ' ' + words[i + 1])\n",
    "                i += 2\n",
    "            else:\n",
    "                result.append(word)\n",
    "                i += 1\n",
    "        return result\n",
    "    \n",
    "    def split_into_lines(words, max_lines=3):\n",
    "        if len(words) <= 2:\n",
    "            return [' '.join(words)]\n",
    "        elif len(words) <= 4:\n",
    "            mid = len(words) // 2\n",
    "            return [' '.join(words[:mid]), ' '.join(words[mid:])]\n",
    "        else:\n",
    "            third = len(words) // 3\n",
    "            return [\n",
    "                ' '.join(words[:third]),\n",
    "                ' '.join(words[third:third*2]),\n",
    "                ' '.join(words[third*2:])\n",
    "            ]\n",
    "    \n",
    "    # Parse text\n",
    "    text_lines = []\n",
    "    if '\\n' in intro_text:\n",
    "        text_lines = [l.strip() for l in intro_text.split('\\n') if l.strip()]\n",
    "    else:\n",
    "        if ':' in intro_text:\n",
    "            parts = intro_text.split(':', 1)\n",
    "            text_lines.append(parts[0].strip() + ':')\n",
    "            remaining = parts[1].strip()\n",
    "        else:\n",
    "            remaining = intro_text\n",
    "        \n",
    "        if remaining:\n",
    "            words = remaining.split()\n",
    "            grouped = group_words_with_prepositions(words)\n",
    "            text_lines.extend(split_into_lines(grouped))\n",
    "    \n",
    "    # Build line configs with rotations\n",
    "    rotations = [4, -3, 4, 4]\n",
    "    \n",
    "    lines_config = []\n",
    "    for i, line_text in enumerate(text_lines[:3]):\n",
    "        rot = rotations[i % len(rotations)]\n",
    "        if len(line_text) > 25:\n",
    "            size = 85\n",
    "        elif len(line_text) > 15:\n",
    "            size = 95\n",
    "        else:\n",
    "            size = 110\n",
    "        lines_config.append({'text': line_text, 'size': size, 'rot': rot, 'is_cities': False})\n",
    "    \n",
    "    # Add cities line if available\n",
    "    if cities_list:\n",
    "        cities_str = ', '.join(cities_list[:4])\n",
    "        lines_config.append({\n",
    "            'text': cities_str,\n",
    "            'size': 50,\n",
    "            'rot': 4,\n",
    "            'is_cities': True\n",
    "        })\n",
    "        print(f\"[DEBUG] Added cities line: {cities_str}\")\n",
    "    else:\n",
    "        print(\"[DEBUG] No cities to add\")\n",
    "    \n",
    "    print(f\"[DEBUG] Final lines_config count: {len(lines_config)}\")\n",
    "    \n",
    "    # Sticker strip styling\n",
    "    BG_ACCENT = (241, 156, 28, 255)\n",
    "    TEXT_BLACK = (0, 0, 0, 255)\n",
    "    \n",
    "    def create_sticker_strip(text, font_size, rotation_deg, is_cities=False):\n",
    "        font = get_font_object(FONT_PATH, font_size)\n",
    "        \n",
    "        ref_bbox = font.getbbox('–ô—Ä–ê–ë–í–¥—É0123456789')\n",
    "        full_height = ref_bbox[3] - ref_bbox[1]\n",
    "        \n",
    "        pad_x = 24\n",
    "        pad_y = 6 if is_cities else 18\n",
    "        \n",
    "        text_bbox = font.getbbox(text)\n",
    "        text_w = text_bbox[2] - text_bbox[0]\n",
    "        content_w = int(text_w + pad_x * 2)\n",
    "        content_h = int(full_height + pad_y * 2)\n",
    "        \n",
    "        img = Image.new('RGBA', (content_w, content_h), (0,0,0,0))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        bevel_ratio = 0.25\n",
    "        b_len = content_h * bevel_ratio\n",
    "        points = [\n",
    "            (0, 0),\n",
    "            (content_w - b_len, 0),\n",
    "            (content_w, b_len),\n",
    "            (content_w, content_h),\n",
    "            (0, content_h)\n",
    "        ]\n",
    "        draw.polygon(points, fill=BG_ACCENT)\n",
    "        \n",
    "        ref_center = (ref_bbox[1] + ref_bbox[3]) / 2\n",
    "        ty = (content_h / 2) - ref_center\n",
    "        tx = (content_w - text_w) // 2\n",
    "        draw.text((tx, ty), text, font=font, fill=TEXT_BLACK)\n",
    "        \n",
    "        if rotation_deg != 0:\n",
    "            img = img.rotate(rotation_deg, expand=True, resample=Image.BICUBIC)\n",
    "        \n",
    "        return img, rotation_deg, content_h\n",
    "    \n",
    "    # Create all strips\n",
    "    strip_data = []\n",
    "    max_strip_width = 0\n",
    "    total_height = 0\n",
    "    # Dynamic spacing like preview: 15% of content height\n",
    "    \n",
    "    for cfg in lines_config:\n",
    "        strip_img, rot, orig_h = create_sticker_strip(\n",
    "            cfg['text'], cfg['size'], cfg['rot'], cfg['is_cities']\n",
    "        )\n",
    "        strip_data.append({\n",
    "            'img': strip_img,\n",
    "            'rotation': rot,\n",
    "            'orig_h': orig_h\n",
    "        })\n",
    "        if strip_img.width > max_strip_width:\n",
    "            max_strip_width = strip_img.width\n",
    "        total_height += strip_img.height\n",
    "    \n",
    "    # Estimate spacing for total height calculation (15% of avg height)\n",
    "    if strip_data:\n",
    "        avg_h = sum(d[\"orig_h\"] for d in strip_data) / len(strip_data)\n",
    "        est_spacing = int(avg_h * 0.15) * (len(strip_data) - 1)\n",
    "        total_height += est_spacing\n",
    "    \n",
    "    # Scale up if block < 80% screen width\n",
    "    target_width = int(W * 0.80)\n",
    "    scale_factor = 1.0\n",
    "    if max_strip_width < target_width and max_strip_width > 0:\n",
    "        scale_factor = target_width / max_strip_width\n",
    "        scale_factor = min(scale_factor, 1.5)\n",
    "    \n",
    "    scaled_total_height = int(total_height * scale_factor)\n",
    "    start_y = (H - scaled_total_height) // 2\n",
    "    \n",
    "    # Animation timing\n",
    "    HOLD_TIME = 0.8\n",
    "    FLY_DURATION = 1.0\n",
    "    \n",
    "    # Premium easing with overshoot\n",
    "    def ease_in_back(t, overshoot=1.70158):\n",
    "        return t * t * ((overshoot + 1) * t - overshoot)\n",
    "    \n",
    "    strip_clips = []\n",
    "    curr_y = start_y\n",
    "    \n",
    "    for idx, data in enumerate(strip_data):\n",
    "        strip_img = data['img']\n",
    "        rotation_deg = data['rotation']\n",
    "        \n",
    "        if scale_factor != 1.0:\n",
    "            new_w = int(strip_img.width * scale_factor)\n",
    "            new_h = int(strip_img.height * scale_factor)\n",
    "            strip_img = strip_img.resize((new_w, new_h), Image.LANCZOS)\n",
    "        \n",
    "        strip_w, strip_h = strip_img.size\n",
    "        \n",
    "        init_x = (W - strip_w) // 2\n",
    "        init_y = curr_y\n",
    "        \n",
    "        rad = math.radians(rotation_deg)\n",
    "        fly_distance = W + strip_w + 200\n",
    "        \n",
    "        direction = 1 if rotation_deg > 0 else -1\n",
    "        fly_dx = direction * fly_distance * math.cos(rad)\n",
    "        fly_dy = -direction * fly_distance * math.sin(rad)\n",
    "        \n",
    "        stagger_delay = idx * 0.06\n",
    "        \n",
    "        def make_fly_out_transform(ix, iy, dx, dy, hold, fly_dur, stagger):\n",
    "            def transform(t):\n",
    "                if t < hold + stagger:\n",
    "                    return (ix, iy)\n",
    "                fly_t = t - (hold + stagger)\n",
    "                if fly_t >= fly_dur:\n",
    "                    return (int(ix + dx), int(iy + dy))\n",
    "                prog = fly_t / fly_dur\n",
    "                eased = ease_in_back(prog, overshoot=2.5)\n",
    "                return (int(ix + dx * eased), int(iy + dy * eased))\n",
    "            return transform\n",
    "        \n",
    "        pos_func = make_fly_out_transform(init_x, init_y, fly_dx, fly_dy, HOLD_TIME, FLY_DURATION, stagger_delay)\n",
    "        \n",
    "        clip = rgba_image_to_clip(strip_img).set_duration(DURATION).set_start(0)\n",
    "        clip = clip.set_position(pos_func)\n",
    "        \n",
    "        strip_clips.append(clip)\n",
    "        \n",
    "        # Proportional spacing like preview\n",
    "        buffer_y = int(data[\"orig_h\"] * 0.15 * scale_factor)\n",
    "        curr_y += strip_h + buffer_y\n",
    "\n",
    "    # Dimmer\n",
    "    dimmer = ColorClip(size=(W, H), color=(0,0,0)).set_opacity(0.5).set_duration(DURATION).set_start(0).crossfadeout(0.6)\n",
    "\n",
    "    return CompositeVideoClip(grid_clips + [dimmer] + strip_clips, size=(W,H))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scene_generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6. –ì–ï–ù–ï–†–ê–¢–û–† –°–¶–ï–ù & OUTRO\n",
    "# ==========================================\n",
    "def create_advanced_scene(image_path, text_data, start_delay=0.0):\n",
    "    T_ENTRY = 0.45   \n",
    "    T_HOLD = 1.2   \n",
    "    T_MOVE = 0.75   \n",
    "    T_INFO = 2.5    \n",
    "    T_EXIT = 0.45    \n",
    "    TOTAL_DURATION = start_delay + T_ENTRY + T_HOLD + T_MOVE + T_INFO + T_EXIT\n",
    "    \n",
    "    # –ó–∞—â–∏—Ç–∞ –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç (—Ö–æ—Ç—è –º—ã –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ –≤—ã–∑–æ–≤–∞)\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Warning: Image not found {image_path}, utilizing ColorClip placeholder.\")\n",
    "        img = ColorClip(size=(W, H), color=(30,30,30)).set_duration(TOTAL_DURATION)\n",
    "    else:\n",
    "        # Load via PIL to force RGB(A) frames even for grayscale sources.\n",
    "        img_pil = Image.open(image_path).convert('RGBA')\n",
    "        img = rgba_image_to_clip(img_pil).resize(width=W)\n",
    "    \n",
    "    def transform_func(t):\n",
    "        if t < start_delay: return 0.4, 'center'\n",
    "        adj_t = t - start_delay\n",
    "        if adj_t < T_ENTRY:\n",
    "            return 0.4 + (0.5 * ease_out_cubic(adj_t/T_ENTRY)), 'center'\n",
    "        elif adj_t < (T_ENTRY+T_HOLD):\n",
    "            return 0.9 + (0.1 * ((adj_t-T_ENTRY)/T_HOLD)), 'center'\n",
    "        elif adj_t < (T_ENTRY+T_HOLD+T_MOVE):\n",
    "            prog = (adj_t - (T_ENTRY+T_HOLD))/T_MOVE\n",
    "            sy, ey = H/2, SPLIT_Y_COORD/2\n",
    "            return 1.0, int(sy + (ey-sy)*ease_in_out_quint(prog) - img.h/2)\n",
    "        elif adj_t < (TOTAL_DURATION-start_delay-T_EXIT):\n",
    "            return 1.0, int(SPLIT_Y_COORD/2 - 10*(adj_t-(T_ENTRY+T_HOLD+T_MOVE)) - img.h/2)\n",
    "        else:\n",
    "            prog = (adj_t - (TOTAL_DURATION-start_delay-T_EXIT))/T_EXIT\n",
    "            sy = SPLIT_Y_COORD/2 - 10*T_INFO\n",
    "            return 1.0, int(sy + (-img.h - sy)*ease_in_cubic(prog) - img.h/2)\n",
    "\n",
    "    moving_img = (img.resize(lambda t: transform_func(t)[0])\n",
    "                     .set_position(lambda t: ('center', transform_func(t)[1]))\n",
    "                     .set_duration(TOTAL_DURATION))\n",
    "    \n",
    "    curtain_h = H - SPLIT_Y_COORD \n",
    "    curtain = ColorClip(size=(W, curtain_h), color=(10,10,10))\n",
    "    move_start_time = start_delay + T_ENTRY + T_HOLD\n",
    "    \n",
    "    def curtain_pos(t):\n",
    "        if t < move_start_time: return ('center', H)\n",
    "        if t < move_start_time+T_MOVE:\n",
    "            prog = (t-move_start_time)/T_MOVE\n",
    "            return ('center', int(H + (SPLIT_Y_COORD-H)*ease_in_out_quint(prog)))\n",
    "        return ('center', SPLIT_Y_COORD)\n",
    "        \n",
    "    curtain = curtain.set_start(0).set_duration(TOTAL_DURATION).set_position(curtain_pos)\n",
    "\n",
    "    text_start = move_start_time + T_MOVE*0.2\n",
    "    sy = SPLIT_Y_COORD + 30\n",
    "    \n",
    "    txts = []\n",
    "    t1, ny = generate_kinetic_text(text_data['title'], FONT_PATH, 90, COLOR_TITLE, text_start, T_INFO+1, sy)\n",
    "    txts.extend(t1)\n",
    "    t2, ny = generate_kinetic_text(text_data['date'], FONT_PATH, 50, COLOR_ACCENT, text_start+0.2, T_INFO+1, ny+30)\n",
    "    txts.extend(t2)\n",
    "    t3, _ = generate_kinetic_text(text_data['location'], FONT_PATH, 45, COLOR_DETAILS, text_start+0.4, T_INFO+1, ny+15)\n",
    "    txts.extend(t3)\n",
    "\n",
    "    return CompositeVideoClip([ColorClip((W,H), (0,0,0), duration=TOTAL_DURATION), moving_img, curtain] + txts)\n",
    "\n",
    "\n",
    "def make_slide_anim(sx, ex, fy, delay):\n",
    "    def slide_func(t):\n",
    "        if t < delay: return (sx, fy) \n",
    "        anim_time = t - delay\n",
    "        anim_dur = 0.8 \n",
    "        if anim_time >= anim_dur: return (ex, fy)\n",
    "        prog = anim_time / anim_dur\n",
    "        val = ease_out_expo(prog) \n",
    "        curr_x = sx + (ex - sx) * val\n",
    "        return (int(curr_x), fy)\n",
    "    return slide_func\n",
    "\n",
    "def create_outro_slide_in():\n",
    "    DURATION = 3.5 \n",
    "    bg = ColorClip(size=(W, H), color=(0,0,0)).set_duration(DURATION)\n",
    "    \n",
    "    words_conf = [\n",
    "        {\"text\": \"–ü–û–õ–Æ–ë–ò–¢–¨\", \"side\": \"left\", \"delay\": 0.0}, \n",
    "        {\"text\": \"–ö–ê–õ–ò–ù–ò–ù–ì–†–ê–î\", \"side\": \"right\", \"delay\": 0.4}, \n",
    "        {\"text\": \"–ê–ù–û–ù–°–´\", \"side\": \"left\", \"delay\": 0.8}\n",
    "    ]\n",
    "    clips = []\n",
    "    \n",
    "    STRIP_H = 210 \n",
    "    GAP = 20\n",
    "    STEP_Y = STRIP_H + GAP\n",
    "    \n",
    "    total_block_h = len(words_conf) * STEP_Y - GAP \n",
    "    start_y_block = (H - total_block_h) / 2\n",
    "    \n",
    "    for i, item in enumerate(words_conf):\n",
    "        txt = item['text']\n",
    "        delay = item['delay']\n",
    "        side = item['side']\n",
    "        \n",
    "        clp, cw, ch = create_single_word_clip(txt, FONT_PATH, 160, BG_STRIP_COLOR, COLOR_TITLE, target_height=STRIP_H)\n",
    "        \n",
    "        final_x = (W - cw) // 2\n",
    "        final_y = int(start_y_block + i * STEP_Y)\n",
    "        \n",
    "        start_x_pos = -cw - 100 if side == \"left\" else W + 100\n",
    "        \n",
    "        pos_func = make_slide_anim(start_x_pos, final_x, final_y, delay)\n",
    "            \n",
    "        final = (clp.set_duration(DURATION)\n",
    "                    .set_start(0)\n",
    "                    .set_position(pos_func))\n",
    "        \n",
    "        clips.append(final)\n",
    "        \n",
    "    return CompositeVideoClip([bg] + clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 7. –°–ë–û–†–ö–ê\n",
    "# ==========================================\n",
    "print(\"--- Rendering Full Promo v24.0 ---\")\n",
    "\n",
    "try:\n",
    "    # 1. –°–±–æ—Ä –≤—Å–µ—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫ –¥–ª—è –ë–µ–Ω—Ç–æ\n",
    "    all_bento_images = []\n",
    "    for scene in SCENES_DATA:\n",
    "        images = scene.get('images', [])\n",
    "        for img_name in images:\n",
    "            if img_name:\n",
    "                all_bento_images.append(img_name)\n",
    "    \n",
    "    # UPD v24.0: –°–±–æ—Ä–∫–∞ —Å—Ü–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ JSON –º–∞—Å—Å–∏–≤–∞\n",
    "    main_scenes = []\n",
    "    DELAY_SCENE_1 = 1.3\n",
    "    \n",
    "    if not SCENES_DATA:\n",
    "        print(\"No scenes in scenario!\")\n",
    "    else:\n",
    "        for i, scene_data in enumerate(SCENES_DATA):\n",
    "            print(f\"Scene {i+1}: {scene_data['title']}...\")\n",
    "            \n",
    "            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫–∏\n",
    "            images = scene_data.get('images', [])\n",
    "            \n",
    "            if not images:\n",
    "                print(f\"  > Warning: No images defined for scene {i+1}. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—Ü–µ–Ω—ã (–∫–∞–∫ –ø—Ä–æ—Å–∏–ª–∏)\n",
    "            main_image_name = images[0]\n",
    "            path = os.path.join(SOURCE_FOLDER, main_image_name)\n",
    "            \n",
    "            delay = DELAY_SCENE_1 if i == 0 else 0.0\n",
    "            main_scenes.append(create_advanced_scene(path, scene_data, delay))\n",
    "\n",
    "    if main_scenes:\n",
    "        print(\"Outro (Slide-In)...\")\n",
    "        main_scenes.append(create_outro_slide_in())\n",
    "        \n",
    "        main_video = concatenate_videoclips(main_scenes, method=\"compose\", padding=-0.5)\n",
    "        \n",
    "        print(f\"Intro Overlay: {INTRO_DATA['text']} ({INTRO_DATA['count']})\")\n",
    "        # –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –¥–ª—è –±–µ–Ω—Ç–æ\n",
    "        cover_overlay = create_overlay_cover(all_bento_images, INTRO_DATA)\n",
    "        \n",
    "        final_video = CompositeVideoClip([main_video, cover_overlay])\n",
    "\n",
    "        audio_files = [f for f in os.listdir(SOURCE_FOLDER) if f.lower().endswith('.mp3')]\n",
    "        if audio_files:\n",
    "            audioclip = AudioFileClip(os.path.join(SOURCE_FOLDER, audio_files[0]))\n",
    "            if audioclip.duration > AUDIO_START_SEC: \n",
    "                audioclip = audioclip.subclip(AUDIO_START_SEC)\n",
    "            audioclip = audioclip.volumex(0.45) \n",
    "            final_video = final_video.set_audio(audioclip.set_duration(final_video.duration).audio_fadeout(1.0))\n",
    "\n",
    "        OUTPUT_FILE = \"promo_v24_final.mp4\"\n",
    "        print(f\"Saving to: {OUTPUT_FILE}\")\n",
    "        \n",
    "        final_video.write_videofile(\n",
    "            OUTPUT_FILE, \n",
    "            fps=FPS, \n",
    "            codec='libx265', \n",
    "            preset='medium',\n",
    "            ffmpeg_params=[\"-crf\", \"26\", \"-pix_fmt\", \"yuv420p\", \"-tag:v\", \"hvc1\"],\n",
    "            logger='bar'\n",
    "        )\n",
    "        print(\"\\nDONE!\")\n",
    "    else:\n",
    "        print(\"Nothing to render.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}